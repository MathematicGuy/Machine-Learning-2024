{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.3: Optimizing and Evaluating Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "      <th>Total Fat</th>\n",
       "      <th>Saturated Fat</th>\n",
       "      <th>Monounsaturated Fat</th>\n",
       "      <th>Polyunsaturated Fat</th>\n",
       "      <th>Trans Fat</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Total Carbohydrate</th>\n",
       "      <th>Dietary Fiber</th>\n",
       "      <th>Sugars</th>\n",
       "      <th>Sugar Alcohol</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Vitamin A</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Iron</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Calories  Total Fat  Saturated Fat  Monounsaturated Fat  \\\n",
       "0     149.0          0            0.0                  0.0   \n",
       "1     123.0          0            0.0                  0.0   \n",
       "2     150.0          0            0.0                  0.0   \n",
       "3     110.0          0            0.0                  0.0   \n",
       "4     143.0          0            0.0                  0.0   \n",
       "\n",
       "   Polyunsaturated Fat  Trans Fat  Cholesterol  Sodium  Total Carbohydrate  \\\n",
       "0                  0.0        0.0            0     9.0                 9.8   \n",
       "1                  0.0        0.0            0     5.0                 6.6   \n",
       "2                  0.0        0.0            0     4.0                11.4   \n",
       "3                  0.0        0.0            0     6.0                 7.0   \n",
       "4                  0.0        0.0            0     7.0                13.1   \n",
       "\n",
       "   Dietary Fiber  Sugars  Sugar Alcohol  Protein  Vitamin A  Vitamin C  \\\n",
       "0            0.0     0.0              0      1.3          0          0   \n",
       "1            0.0     0.0              0      0.8          0          0   \n",
       "2            0.0     0.0              0      1.3          0          0   \n",
       "3            0.0     0.0              0      0.8          0          0   \n",
       "4            0.0     0.0              0      1.0          0          0   \n",
       "\n",
       "   Calcium  Iron            class  \n",
       "0        0     0  'In Moderation'  \n",
       "1        0     0  'In Moderation'  \n",
       "2        0     0  'In Moderation'  \n",
       "3        0     0  'In Moderation'  \n",
       "4        0     0  'In Moderation'  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/food_items.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 18\n",
      "total features: 13260\n"
     ]
    }
   ],
   "source": [
    "features = len(df.count(0))\n",
    "print('total features:', features)\n",
    "features = len(df.count(1))\n",
    "print('total features:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Calories', 'Total Fat', 'Saturated Fat', 'Monounsaturated Fat',\n",
       "       'Polyunsaturated Fat', 'Trans Fat', 'Cholesterol', 'Sodium',\n",
       "       'Total Carbohydrate', 'Dietary Fiber', 'Sugars', 'Sugar Alcohol',\n",
       "       'Protein', 'Vitamin A', 'Vitamin C', 'Calcium', 'Iron', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calories               float64\n",
       "Total Fat                int64\n",
       "Saturated Fat          float64\n",
       "Monounsaturated Fat    float64\n",
       "Polyunsaturated Fat    float64\n",
       "Trans Fat              float64\n",
       "Cholesterol              int64\n",
       "Sodium                 float64\n",
       "Total Carbohydrate     float64\n",
       "Dietary Fiber          float64\n",
       "Sugars                 float64\n",
       "Sugar Alcohol            int64\n",
       "Protein                float64\n",
       "Vitamin A                int64\n",
       "Vitamin C                int64\n",
       "Calcium                  int64\n",
       "Iron                     int64\n",
       "class                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Analyze the target column (last column): count class occurrences and assess class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "'In Moderation'    6649\n",
       "'Less Often'       5621\n",
       "'More Often'        990\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() # count occurent of each value in class fol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "      <th>Total Fat</th>\n",
       "      <th>Saturated Fat</th>\n",
       "      <th>Monounsaturated Fat</th>\n",
       "      <th>Polyunsaturated Fat</th>\n",
       "      <th>Trans Fat</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Total Carbohydrate</th>\n",
       "      <th>Dietary Fiber</th>\n",
       "      <th>Sugars</th>\n",
       "      <th>Sugar Alcohol</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Vitamin A</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Iron</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Calories  Total Fat  Saturated Fat  Monounsaturated Fat  \\\n",
       "0     149.0          0            0.0                  0.0   \n",
       "\n",
       "   Polyunsaturated Fat  Trans Fat  Cholesterol  Sodium  Total Carbohydrate  \\\n",
       "0                  0.0        0.0            0     9.0                 9.8   \n",
       "\n",
       "   Dietary Fiber  Sugars  Sugar Alcohol  Protein  Vitamin A  Vitamin C  \\\n",
       "0            0.0     0.0              0      1.3          0          0   \n",
       "\n",
       "   Calcium  Iron            class  \n",
       "0        0     0  'In Moderation'  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split feature (X) and labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "      <th>Total Fat</th>\n",
       "      <th>Saturated Fat</th>\n",
       "      <th>Monounsaturated Fat</th>\n",
       "      <th>Polyunsaturated Fat</th>\n",
       "      <th>Trans Fat</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Total Carbohydrate</th>\n",
       "      <th>Dietary Fiber</th>\n",
       "      <th>Sugars</th>\n",
       "      <th>Sugar Alcohol</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Vitamin A</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Iron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>140.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13256</th>\n",
       "      <td>130.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13257</th>\n",
       "      <td>140.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>140.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13260 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Calories  Total Fat  Saturated Fat  Monounsaturated Fat  \\\n",
       "0         149.0          0            0.0                  0.0   \n",
       "1         123.0          0            0.0                  0.0   \n",
       "2         150.0          0            0.0                  0.0   \n",
       "3         110.0          0            0.0                  0.0   \n",
       "4         143.0          0            0.0                  0.0   \n",
       "...         ...        ...            ...                  ...   \n",
       "13255     140.0          5            1.0                  0.0   \n",
       "13256     130.0          4            0.5                  0.0   \n",
       "13257     140.0          3            0.0                  0.0   \n",
       "13258     140.0          3            0.5                  0.0   \n",
       "13259     120.0          4            0.5                  0.0   \n",
       "\n",
       "       Polyunsaturated Fat  Trans Fat  Cholesterol  Sodium  \\\n",
       "0                      0.0        0.0            0     9.0   \n",
       "1                      0.0        0.0            0     5.0   \n",
       "2                      0.0        0.0            0     4.0   \n",
       "3                      0.0        0.0            0     6.0   \n",
       "4                      0.0        0.0            0     7.0   \n",
       "...                    ...        ...          ...     ...   \n",
       "13255                  0.0        0.0            0    60.0   \n",
       "13256                  0.0        0.0            0    50.0   \n",
       "13257                  0.0        0.0            0   130.0   \n",
       "13258                  0.0        0.0            0    55.0   \n",
       "13259                  0.0        0.0            0    55.0   \n",
       "\n",
       "       Total Carbohydrate  Dietary Fiber  Sugars  Sugar Alcohol  Protein  \\\n",
       "0                     9.8            0.0     0.0              0      1.3   \n",
       "1                     6.6            0.0     0.0              0      0.8   \n",
       "2                    11.4            0.0     0.0              0      1.3   \n",
       "3                     7.0            0.0     0.0              0      0.8   \n",
       "4                    13.1            0.0     0.0              0      1.0   \n",
       "...                   ...            ...     ...            ...      ...   \n",
       "13255                23.0            2.0    13.0              0      2.0   \n",
       "13256                23.0            1.0    14.0              0      2.0   \n",
       "13257                26.0            2.0    15.0              0      1.0   \n",
       "13258                27.0            2.0    17.0              0      1.0   \n",
       "13259                23.0            2.0    13.0              0      2.0   \n",
       "\n",
       "       Vitamin A  Vitamin C  Calcium  Iron  \n",
       "0              0          0        0     0  \n",
       "1              0          0        0     0  \n",
       "2              0          0        0     0  \n",
       "3              0          0        0     0  \n",
       "4              0          0        0     0  \n",
       "...          ...        ...      ...   ...  \n",
       "13255          0          0        0     4  \n",
       "13256          0          0        0     4  \n",
       "13257          0          0        0     2  \n",
       "13258          0          0        0     2  \n",
       "13259          0          0        0     4  \n",
       "\n",
       "[13260 rows x 17 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13256</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13257</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>'In Moderation'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13260 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class\n",
       "0      'In Moderation'\n",
       "1      'In Moderation'\n",
       "2      'In Moderation'\n",
       "3      'In Moderation'\n",
       "4      'In Moderation'\n",
       "...                ...\n",
       "13255  'In Moderation'\n",
       "13256  'In Moderation'\n",
       "13257  'In Moderation'\n",
       "13258  'In Moderation'\n",
       "13259  'In Moderation'\n",
       "\n",
       "[13260 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, -1:]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize X using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAFcCAYAAAAK4I0VAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAKFoSURBVHhe7J0FYBTH28afy8XdXSAhuDuUQimlLZS6u3v71d3d23/dnbrSllKg0BZ3h0CIE3c7l/3mnb2NkeCSS94fbO52Vm53Z/Z95h3VKQIwDMMwDNOp8XB9MgzDMAzTiWHBZhiGYRg3gAWbYRiGYdwAFmyGYRiGcQNYsBmGYRjGDWDBZhiGYRg3gAWbYRiGYdwAFmyGYRiGcQNYsBmGYRjGDWDBZhiGYRg3gAWbYRiGYdwAFmyGYRiGcQNYsBmGYRjGDeDZuhgJJYPKegvK6syuEOZoEhvqi4ggH/ldp9PJT4Zhujcs2IwUa6fTiS8X5SGnrBEBPnrXFuZo4BRvZJ3RhgfO7I8gPy8p2IdDtPnV71xwxozZGyzY3RyKflpsNhtmLs7H4MQA9Ijwdm1ljgYeHh7Iq7Lg4/+K8OrlQ+HtqZdhhxKK8xqDFWuyq1whzNGkd1wwUqICWLSZPcKC3c2h6Cfv2mw246slBegf54ueQrBJINh4HHkoPmihZ7+r1o6vlpfhwbP6IyrY95CJthbnv68tQkWdCb1jA1xbmKMBxfXcTRU4eWgcjukbJdf53WPagwW7m0PR73A4YDQa8c2yQgyM90O6MOBeXoevKJbpGC0+7Ha7FNX8ajv+2FSFG09MR1yY30GLNp2fFipR+X1NEXz1TozqGcTxfJSxOHT4ZHExjhsQgwlCtDnDzLQHC3Y3RxMITbCHJAWiX2IIfHx82GgcBbT4sFqtsFgsUrSzKqz4a3M1/m96b0QKT/tgMlLa+encvwkP289DFWy9Xs9xfRSg+NAWq9MDHy0qwakjEzAiLQJ6fv+YNrBgd3Mo+jXB/nZZEYYkB2FgShgL9lGERJo8bBJVqqqg9bwqG75eWYaXLhkCL09VXA8kbrT4NplM+GNdMfy9dBifHgZvb28p2syRQzO9WgaN4tnqAF74cxeum5Iq3sNQfgeZVrBgd3PaE+xBPcJZsI8iFCftiXZ+tQ1fLCvF0xcMQoi/2s5gf9HiWxPsQB89JvWPlvHNgn10kELtKlGhqgqLEO03/i7CWaMTMbZ3JL+HTBMs2N0cFuzOyZ5E++d1lbhtem/Ehu5/nXZbwQ729cSkATHw9fVlwT5KaHFC8dxStD9ZUorJIm6O7RfN7yIjObR9RRiGOSSQcSYj7enpKTNPJKi0nhLuhdOGRuDdeVkorTVJET+oPLdLAzQxoE9ejuxC8UqZJS2eqcEnDYVwxTGx+GdLGZZnVh58PDNdAhZshumkkDEnQ95WtNMivXHywDD8b/YO1But0pCzMXdvNNGmtgSaaPt5AldNiMWs1YXYnF8LB4t2t4cFm2E6Oe152iTaZ4+IwkPfbobV5mBD3gXQMmgtRdtHiPYtUxLw/t/ZWJdTzZ52N4cFm2E6OVqxaXvF45eNj8X9X29EZb1ax824L1oR+W6irQceOCVZetpLt1ewaHdjWLAZxg3Yk2ifPzoGHwgPjBousSF3b9qKNsU1iba3EO1rJ8bJOu0lGSza3RUWbIZxEzoS7R7hnjBZ7U2jozHujRbPJNpaPJNo+3oClx8Tg3mbSrAul4vHuyMs2AzjRmjelybatFAYGW7qDsRGvOugiXbL4nES7esmxeG9edloMHGDw+4GCzbDuCGaMScjTt/JZLNYdz1aFo+TaFNGzdPVFc9mVTNoTPeBBZth3BCt2FRbCBbrrgfFc0vRphIVvZ4yaArsdhu3W+hmsGAzjJtDBp3purTMnJGHTeJNOJ1cHN7dYMFmGIZxA7hEhWHBZhiGcSN02niyTLeDBZs5OJz1uGvycZg0adIel9OvvtN1wMFix7vnJMtiwue/X+kK23cWPHOuPHbyZW+6Qph9RhHP/swZmDix/TjWlmOPPRZbShpdBzEMc6hgwWYODsUBo87WNNOQpWEXFi1aJJZVsDhcYWKBzeo64GDRQe/lJ7956PY/+eo9feSnTu8pP5n9QYHRww6L1RWvpgZXXC/CrqK6pri2mUw4tPN+2fHeLdMxcdIJKKoxu8IYpvvB02t2cyj6D+n0mvZdGOGVjNzUIajO3uAKPMSIa6bxs729D0x07TY7PL3cX7CpSw/No2wwGPDyX/m4d3pPBAQEyK5eHcWbFt9N02v6eWJS/xj4+alTde5XfDsNuFAfiG/F1zlbKnHygAg1/JBjxQMTfPDCcj0yi+vRK8bfFd69oLhT49uEu7/NwJNn9kJkWJBsPa7VazNdG45l5tDitLk+288HmiszMWf2XBTVWlG8dSkev/9+vP/d37AJY6QoTpgbyvHzlx/i8UcewpPP/w+rt+aLU7U+V11RBv6ePxcVdUa57rSZMH/2bKzaUSREzIaVc77F/eK8L7/3HarqzbKPsoalZhcW/j0XGQVVrhBgw/J/8e/KTeL3HchZ/TeeePRBPP3S+8guqWt1LKE47cjZ+B9eff5pPP/am5jzz2IsXbpKLMtQWFnj2qubIOKriQ76A9Pz2rl2IZ579GHc/8gTmLVgrTrrlGs7QUJUlb8Z/3v+MTwi9vnlz2WwO9R9rLXFWLViGXYuVfdbup6e9XJkZJeoBzNMd0K8BEw3Rnhpis1mU+rq6pT352xTVmzdpQiPTbHb7XLbfmPJVoaLZBXWY7AroDVbP7+B7LAyOP0Y+akuicqOGrPywiV9W4Rpi6fSZ/AditHuOoFg/nOnym2f/LtTrhtKdyrCMVT8Y6cpxyZHtDrePzxO+XlDqdyPyPrlMRl+yhNzXCGKMm1ksuIV1Fe5oH9qq2O9fAOVR//IdO0l5LyxSJneJ6XVPi2X8x5/17XnkUF4yorwlJXKykrl/plrlerqasVisewx3rT4rq+vV77+d7vyx8ospaGh4cDi216vXOC69zmbyl2BzRiKNyn9eybs9pzCe41SMutNrr0U5fOHp+62T8KwuxSruJys3x/ebRstY2ec6zq6+0DxYzablaqqGuXKt5cpu4rLZfxTOmC6B+xhM0cUnYeX/MyrX4rE46/DkhUr8O6b9yLKz4lacyBuf+xFrM/MQ119HTbP+wF9YceOTa9hfV6zR6zTqeeAQ/0QAfLDWDoHG3164pNvlqIwLwO3n9UfxuoSvP3C63K7ROcqCre1KPrVecDWsB0/7arDU6/MRn5+Dt548ALYzI147dKLUG9Rf2jht2/hzx35GHPenSiqbEBNWS4uPW2s2OKBZ3/8B2/ffqncjyGceOq2a7EttwiX3Ps8Sqrq0VBTgrfuPgPVWasxdfrrsAin3Fa5GZc/PR8enkOxNq8CRmM91s77FTeeN0gW/yVOuBnr1q3ChT3Fioinn/5eIdbX4Ys335C/wjDdCRZs5qgQ4HciNs57H8eMGYMbbrkVYT5+ePaH1Xjt8XswND0FwUHBGDj1HDx4z2S5v9HqKmrfE4GpmPXbbFx5wXgkpPTFa5/9gJ5+QGZRrmuHPeAdjld/WIaH7pyO5OSeuPWRVzA5HDDbaMxm9bc3ZWeLv2F4/d3nEB8RiNDoHnj49htFmBM5FUBkSIDcjxFCXCYyYj+sREL/k/DlC/chNjwIgaGxuP7x15EgtucvuR+F9VZZhUHokITE6GD4+QVh+NTT8dD9l0Mv8lQ+4phhw4YgJZ7yZToMHjhQrA9Deo9YeRzDdCdYsJmjwlkPP4bwtk2JFSeMDTXI2r4FCxfMw5y5s7Fs1T/qNs2b3hNDzsL4vtGuFUFQMqKF6O5T87L4wbjypN7NPVx9IzCoFwlJ80viJVulW5FTbJDlslQ6uytvp/wWHx8qPxmV0s3rUCc+LcYcfPzuu3jXtXz8xS/ooe6CsmqjEOQknBkWBIf9d8T4j8K3c5ejrtHk2oNhmJawYDNHB4vrswWLPn0WScnJ6N1vEKaccBKmnzwD7/3n2rgvqG3QDox9cOBnTBkn/hpw2Zg03P/cZ/jfPRfhzJufF955AE4dlqLuxEgcdrUbX6XI0Fxz0024ybXccNPtWCq3AGGBPuLZReGLzM248YS+ImQTLjx5PJJFGnh99g51J4ZhmmDBZjoFxoIlOPvqR9Bo88DH85ajrKIK9Q31+PDWoa49jj5/L1gsP+N6BOLFB6/EHS9/C7+IUfjs26UYlhgmtzEqem+1ncHQY+6A1WKB2WxuvVis6Bet9qcPjEzB2/O2oWDnZrx432Wor6nEPRdNRH4997lmmJawYDOdgpqCbFSKz/C0h3Dp1LGIjgxHUKCv7C/cOXBg6/qlCIhLw5LF21FTVYXK6hoU7VqGy88cIutbmWZi+g9FiPgsKF4Ii2uWqVaLS9CpGsThVOunk3oNxD3Pf46HTkmCza7A5lArHjRozUQ7M0w3hQWb6RT4BATLz/r8F7BmSw7KSnbhw6evwv991FmKRvXo2XswDCXZSIkIQFhEBHr3Goljxo/H1bc/gVXbC8FS0ox37LG46ox+qM7diPAZd2PDtp0oKSlG1rZN+PqDF3DKnV/DLvbb8vNT4rmegYVLN6GkrBSbV87BgjW7oPfQwaspE6SDZ7CQf6cTX373J7ZvWI1lq9a5tjFM94EFmzm0ONqtnt6NtuIWOexMPH7RSBjrqjFuUBpi45Nx3SMzXVvbpz2BbBvWkYi29t1U2rZra1utPWbkaNc3YPLw4dDr67Fq+XJ88vrjGNMvCX9vKXNt7SaIh9jg+toeL37yK6hCwzb7FQwb0Bvx8QlIHzAEF19/P/5cReUplFHTY1f2LEyZMATxsXEYPHY6VojHmHTvZ0gKVYvMAS+cc/PT4lPBS3degH7DRuOBZ75RNzFMN4KHJu3mUPQf0qFJFRs2r1oiDHkIxo8Z7gpsxlSZj+VbcpHcbwR6xQS5QlXsViO2rlqF7YWlUPR+6DtwGPrE+2Ll6k0YMn4iwvy95X51RZlYvbMYg4aPRUywL5w2M5YuXQFneA8cO7hHi1yoE+tXLoHNNwqjh/STIZaaIizbuBPRvYZhQCIV2gJb161Cud0HE0cPaTEGtoKcTUtRWAeMHTce3pY8jIpLQ05wOrZmbEVskFqkS9f82zMX4ewnZ+GJD/7Do9dOlOFHAufRHppUcaJgwxLk1CkYOmY8Qv1cxdwtsJnrsWPtBuwoKoHZ4URwaAR6pPVCemoP+HqKmFIcKNuVg03bMlFV2wAvv0D06j8Yg9OTm1vsC+SIaZtWYnN2CTw8/dF3yBj063G4hkLtnFDc8dCk3RsW7G7OIRfsLoop/2/495iK5D6nInvbLHh6qM/FaW3AM6eOwaPzMvDq9+txx7lHrpHcURds5ojCgs1wLDPMPuCXMBjTesSgYMfv8Bp9Ah57+lk8/+SjmHLMWCnWif3H4uypqhfPMAxzOGDBZph9wTMaP69bizsuORnRuzbj7f+9ipffeAfbdlXh0nveQeb6JUgOVafuZBiGORywYDPMPuIbloBXvvgTRYVFKCwsdC1F+OLFG+HnfWhngGYYhmkLCzbD7AdUx+vp5QVfX1+5eHmyUDMMc2RgwWYYhmEYN4AFm2EYhmHcABZshmEYhnEDWLAZhmEYxg1gwWYOCTSdYk52LnJz1SUnKxsFNLqVfV8msmbcCyeKC/Ka4jo3Kwu5+YVoMKlTajIMc3hgwWYOCbtWfobevVKRmqouaem9kJIYDz+vRFx71zPYmq+OHb3/KKgtysbmzVvRaGbx7ww4yldiQErPprhOTU9Hao8kBPuHY/oFt+KfdVloM9HWPuJE7s4M7MgucK0zDNMSFmzmkNDYUCknz0ifeiHefPNNvPbKSzhjUhRCgurx0asPY2CPMVhRYmp30o0948T3l6dj8OCB+HNTuSuMOZpYjLWoFZ/B8T1lXNNy3QXHIDxUjznfvYXjR6TjhU9XHUBcm3DV5P6YdM61rnWGYVrCgs0cUiaeOA233HILbr/zbvz8TxmKCwtw3rQxYksOTh4zEg377SXr4O2aI8Tb21P9wnQKYhISZVzT8v43S1BSXITvXrtZbnvoxilYmFUnv+87ntB7i79e3LedYdqDBZs5pCgt/CoaZMQ/OAJffvMtjksA6nbtxE+bCtWNDjNmffYmzphxIsaMGIaBAwfjmEnH4/pbvoXNVZ5am70U06ZNxwu/qusP3Hg+Tj55Os69+EpYaB+7AR+88iRmnDwFo4YPkeeYOOUkPPHifLk/c5hp40J7+wXinFtewi1jQwBrI97730fqBkXBlkW/49yzTsUxItM2cOBAjBx7DM4+/1mUGdQM3I5f7scp02dgbS5QtG0Vpp8yXcT1NHw6d6ncXl+WjUsuOh/HHzseQwcPwpBhIzFtxoVYlVMvtzNMd4AFmznseIf0wC13kudlw4vfLJdzVGfMfg1nXPl/WLKtHCl9BmDIwDTkLvoHH7x9KV7+a6s8TnHY0dDQ2DTnsqXBAKNRrDdapFYsfv1yXH/3Y9i0qxG9BwzFoL7J2LJwHh6/7xx8sfFA68yZg8HD0w/PffY+/MX3/zaulXOKO2xVmHHaaZizaD3CEtMwcsQQmNavxs/fP4TLb35BHuewmNFoaFTnILfZxXejiGsDTBa7CLDixXN74atvvofZN0yI9XDE6K34a/a3GJM2Fjk1+zIDO8N0AWh6Tab74nQ6FZvNptTV1Snvz9mmrNi6SzEYDIrdbpfb9pXNc54hDVWueulzV0hr1n33htyOiS8oFrFetOlv5fY3vlE3ulj/w5vqPsc8IfdRcSifnqGT4b+sr3CFqWz/+1PlhW/mudZUZj16o9w3+tyPFLsrrKvicDgUk8mkVFZWKvfPXKtUV1crFotlj/GmxXd9fb3y9b/blT9WZikNDQ37Fd+G3D/lM04feawrpA2WHCVVL+Kx5zSlXqw6bI3KLU+8rJTVmdXthCFTSfX1VJBygtxHxapM6QklYeR017qGXfn+zQeUVbnVrnWBrVa5OjZIXscXi7NcgV0bih+z2axUVdUoV769TNlVXC7jn9IB0z1gD5s5IgSGBKpffD1BMy7HD5qC1269QA1zkTpilPrF6SX3USGb7MLZuv67z5QrcO8FU11rKmNmTFC/tDoHc0TxDoN/gPj09ADVRnt4BuDNR+9CdHCL2cz805HSN0ZEr17uo+LqFuakMpiW6HHuLc9iVI8w17rAMwQX3DlFfvVgM8Z0EzilM0eE6rpq9Yujua9uQ8VOPHz1cRg/bixGjhyJiade5Nqy75Rmr8FtF0/CuLHqOU646E51QwudZ44w1hLUGMSnyGA1RYOtFh89eyMmHDMeo0aNxKjRI7Eqo8i1cR9w2rDiz89wytRjMWb0KIwU57juxV9dGxmme8CCzRwRMjevlp8XnDMeXuJz+9yvkB7dG8988h98o9NwzIQJGD+yv9xnX1n64XPo32sU3vh5HeJTB2CCOMeYwUmurczRomT5HFQ7gCGDU0COtqMxH+Pje+Lah95DAUIxdvwxmDhpEkL81P33ir0Bz541FeNOuRJ/ZtWj/9BRmDhxIvrHu7YzTDeBBZs57NSXrsXzT38HnWcQbjp5sAyb+c17KIMPnvxzOxbO+gqv/+9/eP6xh+W2DtG1LuR+/vNPUYNgfLRgC376+mP8T5zj2fvvcG1ljgZ2Sy2uP+NxmMT3SWNnyLDM31/A8spazLjpZRQs/RNvvv46XnnpFfTpkSi370abuoza7JV4aNZ/8PDohaINK/HpB+/g1VdexR2XnuHag2G6ByzYzCGFmkUoigKn0wm73Ya6ip04/cQTsU1sS0o7B6OTQuV+FoMw6X5RuPz4XnJdUZzIy1kuv3dERnEl7QinwymLWu0WKxDeD6eMUg2/4nRg08a/5XfmSKBrimuHww5DXRmeuHwUfq9tgLffKNxxsyrYhioaZgUYM05tX0DHmBp2oqzM1cWvBRSvRdV1MDvFNzq3WGwms9ymG3AJIoLUenC7tQYL/+EicaZ7wYLNHFJ+fOEu9O7dWy690lIRH98P/26uRp+RE7Fu7fvwcbUwikhNB0yFGJraC5/98CsuO/8UHHNKe96xB/pPOU1+e+Gyqbj1qosxatwxsh92YFQMUL0S40cdi9/++gsnHDcOp970qdyXOfzkbl6FPq64Tu+VhuSkNDz9XZbc9u/6WehB5eGC1GMmy8/nbjkFD7/xBV5/9g4kJ/TFthIZ3AI/hCf1FCdejaHDhuGKIYPw+o9zEZqYIrc6Nj+Oc29+DN/NfAdpqb3x7J8ymGG6DSzYzCEhPLEPfERqaqgqR1ZWFrKzd8HpH4UzL7sZn/zwJ1Yt/gcRAVR7rXLrPc/j/849HjXFebjyvDMx84d1uPLuJzGWNvrKXVzoMPra93HOqDjUVRfjrc++QYFjPDx0wIfvfYSLJw5F7sblOH3aNCxcXI67n3gKA+iwVudgDiU+ET3QO5hKOMzYKeM6G7Vmf4w/8Wy8/M7HKKoxY1yfONfeQNiQq/DOkzfCu64Kz9x2Oe54+B2MP+deXDKkLw1u1gIPPPLgU0gPt2PHpo34fPNWOD2j4BU5COvnfYE+Yo/f33sKF1x6M+A/Aq+/cI9sD8FWjOku6Khvl+s70w2h6Hc4HDAajfh2WRGGJAdhUI9w+Pj4wMPDQ45WdvhQYKitFsbehpCQcAT6eUNxWGFXvODlufvv1lZXiW2eiIwIcYUQTjRUV6Peakd4RBT8vPRw2qxweHijq49wSUXRVqsVBoMBL/+Vj3un90RAQAC8vLw6jDctvk0mE/5YV4xgP09M6h8DPz+/wx7fVmMjquob4e0bhPDQAOicdtjsCry8mzNyhF3EX01tHbx8AhEa3NwyTVEcqCyvFHHrhciocHhScbnFAr2Pr8zAdXUo7tT4NuHubzPw5Jm9EBkWBG9vbxl3TNeHY5k5iugQEBqBhNhYKdYyRC+Eth2xJkLDI9qINeGBoPBIeQ4Saxni1fXF2h3x9g9EnIinCBJrCvDw3E2sCU8Rf1FRUa3EmtDp9IiKiUEsibUaAC/f7iHWDEOwYDMMwzCMG8CCzTAMwzBuAAs2wzAMw7gBLNgMwzAM4wawYDMMwzCMG8CCzTAMwzBuAAs2wzAMw7gBLNgMwzAM4wawYDMMwzCMG8CCzTAMwzBuAAs2wzAMw7gBLNgMwzAM4wawYDMMwzCMG8CCzewRmtKPl865MAzTveD5sLs5FP0t58PuGx+Afkmh8PVW58NW50GUO8LqcMJT7yFyeSKQpzQ86ihOESc2m5zb+s2/C3DfKZ17Pmzm4KC44/mwuzcs2N2cloK9fEclNhU2Qq/XS8NNtpu2O4UwZJYYYLU7ERXsjdhQH7GNjLvrJJ2UI5Wyj+ZzcDqdcokI9MIZI2IPWrCZow/FkV28cxD/PfVqPGrxyYLdvWHB7ua0NOCNjY2w2+1SsD09PaWRIDEgL+7TxWXIq7YhIsATNx8fCz8fr07lkdF90LK1sB42kbE40tBjSI70R3ggZWaOzDPR4s4m4ofigsTa399/vwS7zuTAgMQQeIpj9Gz0jzoiFUMR79yGvDqU1phx3IAo8a7Ru0jbAIfdAbPFipnLiliwuyEs2N0cin4SZYvFIr1sysFTmGYAaBuFV1TX47N1NpHzByak+WPqgDAp7J3FUNA1U2bjuV+2o1dMoCv0yFFUa8KEvpEY3SviiGVk6J61hUSaxNrX17ephKQ9aF9NsLNL67Ayu17s73HErpnZA8ISO50OGM0WbNhlEnEFJIV5ISnSDx56VwZaccIpXkJPPXDKkCgEBwWyYHcjWLC7OVr0k9iRp0afJNIaZNxJsMvLyzF3hxVZNToEeHvgvmnxshiVPPHOAF232WzGW/PycNmkVFfokWN5ZgXCAzwwvk+0FM8jYUC1uCNDTvFAv0ufe/ptOobilwTbYDDIDBoJ/J5EnjkyULzQO/jtygpklFnh46nDNaN9EREWIjNiFK/0PtJCUAZNqwJhwe4esGAzTYafDAYtLZOEZtwrKyuxq6QK321VYHPqcEyvYJw3Pknm7o+2oafrJUNXW1uL9/4txdVT0lxbjhzLtlciwNOKiQPipCE9kgaUnj8t9Jva946gZ0ULCTXFK31SHO/tOObwQnFCQpxX3oCPl9XKsNGxFoxI9kd4ePhubQzoO6UzHx+fpuorpuvDgs000V5SoDASw7q6OpSVleG/TAPWlYqEI7Y9dlY64iKDj7qXTYJDwkOZig+XVOLaE9JdW44cS7dXwEcxYvLgBAQGBkqP9WiwL4ZbEwcqlaCF1tkMHF0oDVO11OdLSrC91Axf8Uqd09eO+JhIhIWFSQ9bi1v6pPRF751WOsJ0D1iwmT2iGXfyxqqqqlBQUomvNtiFlw2M7xWKiyemyFz+0SyS04xdRUUFPlpajeumHnnBXpJRDm+nQQp2UFBQpy9ipnil50afbAKOLvT8KeO0Ka8aH/xTKMNOSnViQFIwoqKiZHpq6UXTZ9uF6R5wxQezR8gYkBiTKFN9WUSwH45JUQ3Esqxa5JU1SEHvNEaftWefoHjVvDRejt5CcUDvF2WeFmytknHj5wX0iPRGcHCwLK2haietfYJ2jHYci3X3ggWb2Suacad6NDIgvSKEsXDZifmbK2SROXtq7gvFLy9HZyFIrNfn1SCn3CSrmqaleyAkKLBJrOnda+84pvvBgs3sFTIQlJsn40FGJCw4AFPTVKOxaVcDMovrm1quMgyzb2iZXGp/MWdDhSwcig0E4kM8ZTG41jKcBZrRYMFm9gkyGpTTJyNCop0qvOxQX+EdCCsze0N5U2tj9rIZZt+gd4Xqrsm7Lq2zylKr0Uk6+X5xdy2mPTg1MPsMGQ8yImRMgoRRGSuMC5FdZkR2qVqXzTDM3iGxpgxug9GCzxcVy7DUMCAl3EcKNrUZ0YrCGUaDBZvZZ1p62VRk1yvSC/FB6rbPFxXKIRPJCDEMs2dIsCmDuzanGk5XqdTweI9W3jWLNdMWFmxmv2jpZZNxGSGMDFFrtGNbQW1Tv16mM6OgptqIXeVGVNbb0CqLZbOjos7qWtl/HDYHXv8tH5Um98i4mY1W1DTuZ8mQ3YYvf98F00Gkc8rYVtYZ8euaMrk+IEqH+DC1uknrJsmCzbSFBZvZLzQvm4wKGZceEV7oGaaTDWa+Wl4ii/i4LvswIp7rtu3VWJJndAXsHw6zFW/+kIUbPs3BfTNzcPOHmShsoc/v/5yLWz7KxO85FleICxGnK9dXYH2V3RXQDsJj/O6vXCzbaUCVQYig4sCiVRX4bXU1rE36rWDjpgr8uqoSBvs+pBGnHf+sqUBWw6HPADiNBtz+biZu+3wnGm37nl4NDRasz67DTZ8XoMG6f+lcKwqnjO2SHVWwuJ7BsHi17ppGL6OuWyzWTHuwYDP7DRmTll728Dg13GBxYENeDXvZh5nZy8qxKPfABHsnif0uK847pSe+unMgPr25DxK9XRsFadF+SIn0RXJ4m9HrFDu+WViG9RUdC/bmLRWYtdOMy85OQ59IL5FQ9HA21uOrRcVYW6JmACqL6/Ds/DL8U+yEr+c+iJLdim//K0P2YRBsD18v9IvxRWqMH7z2wxIGhAXi3nPjYaxqwDebG/a76z8JdnWjGf9sU/tdD47RISpE7TLJddfMnmDBZvYbMiZUZEfGheqyE8OF0QtTt/28ulTONsRedsfQczE0mPDjggIhRiUoqqV+7K6NAofVjmVrS/H53F34dXkZ8mtVkSwvrcfaHbWoFu5qcYUR6zNrsHZ7DbaU7nsRdkG9FT6BPji7b4Ds8+vv6ymNgN3mwKodNQiLD8TF46KQEtBsGnbm1orfrQdlEXbk12Ed/W5GNfJqmsVbUaz45u9KRIYG4aQUH1cocOz4RHn+/31bgHqHEz/NL4K3+M1nT4nEngbUdIp912SI38msB93dthy6BrG+rRpVRlW8LfVGrNhaC7NDeOHLijFzYTEMDkUVUPFAa2qMWCDCP59bgIVbamGhLg0SBZVlDVi904BjR0finKHh8GxhCRtrDPK8ViGqv/9TiO+XlMv5qVum5tiEMFwWDSz4twCZ+5iZoHinhcYtmLW6BFbhXdMQpGMTId8jGueAxZrZE/rHBa7vDLNfkGEhA0QedZCHCdvKAWH34alT0Cs28IgV7dE1UAMemlVsXYEJI9IiXFuOHAWVBugVG3rGBO+1DnLVxhI8/GMxyhweqCpqxHdrqlDj4YMRib5U3oqbP8rBsl1m+Ol12JRdjzIfX2HUfbF0SQG+XFOHcrMThjoLNucbsDanAQUefpjcQxzbIQqytpTj74wGbN5lQEmtA4p4Xtty67GjzIo+if4wGcx4ZlYhNghhnr+9DjGpEUgLUlXsq7/yMWdbI+qEGNaWm7Alv1H+rjMsCENjVPc8f2sFvs824YaL05Ds13zfHiINnNDTA3M312GpEOCtNU6cNyMVg4QHvqeUYReZlud+KcDqXCOoirmk2CDuV/xuVj16iNxhYrAeRVkleOqvCvy9tgobyizYWWjEL2uqcdyQCATAgv97LwerqmzwEulzzqZazMsyY8bQUJmB2Li8GJ+srcXyreK6Cgw4aXgkvF2jAW3PKMaLIvPxx/pq7BKZqbV5jfLZTR0cJjxx7ap1SO8fhHmrauAT5ItB8Xt6/s1QOq0RGY3vVhRD5EkwJFaH3nEBcrxwKg7nxmbMnmiRr2SY/UPzsqkoj4r0qC6bWJJZC4PJIo0TiSnTApsVsxZXI1FkKt64NBUv3NQHxyd4CY9VLR41VhuEB63gwlNScf/5aXjj5gG4bXSI3Hbiyen44OZ+GBPqicHDYvHBLf3FMgBPHBcqt++J0kITMktMKGu0Q3E6xXejXN9eZAb5yYHB/vjopv54/cIY9YAWmvF/F/bBBzf2QrL4PvWUNPV3bx2AywcHqDsINorzeAnPfXjo7iYlJDYCE6K8UFFnR0pyCM5I892jWBNevl5456Z++OD6nqDs12UXiGug371tIMYkuMrwXSfp1zcSb17fD8+dHQfF7kBxg7gjTx88d3VvfHVTXzxyaR88PD4YBpGpypOFETqMm9oT79/YD1eMab6HZtQTnzQpCW+Ife6eHIpGgw3mNvXcOi8/hId4YGeV2RWyZ6jUySYyD18uKZTedbAPZKNNzbumDC7D7AkWbOaAIC+AFjIy2pClk3ro4KMH6k12/LGujOuy28FSa0C2EA2zxSaLcL/4uxTlFkWIgVqs6hMWgHBfHT7/NRuv/lmExZkNsBx093YdJpzcAw9fkIozBgcLj9AHD52biocuSMODZyWgRRX2ftfHahjtTkQEe8HLtd6WepfYGUw2mOS3fWVvV6THVZNjEOipQ0xsMK44NhqJgWphe3mFAV/OLcDbv+fjtwxXnX+b03VcmO2Fs4aEgCQ0Lsy/wwxGpLceNdTAbi/Qe0CCXSYyZDtL1WsZKPJGwUFqOxAaRZBbhjN7gwWbOWDIuLSsyw4O9ENquGpwVufUwWRmL3s3XPbYJrxAo8jYGMQSGeqLCcn+MlwfGIS3rknH+QMCkJlfj7eE2Dw4u3x3YdmDXVecChxN9bVtoPCDiI+OftZLr4OxuSl4M+K3dm3ahbW1dgxO9EVVhREv/Ve732mi49vVQe+yYuSVTxsdjQh/PTatLsYTvxVhVZEN0eFeCPPef1O3h0fcBHXtChW/tzdIrK1WG75aVijrwwNFLmlwrJ7rrpn9ggWbOSjIyJCxIaNDxmd8sk62uDVaHfhhZTF72W3wFpY6WHwGhvjj+hkpuPFUdbn2pHh1B4HexxtnndQDb1/XB+dF61CU1YCW7ZqoVLei1qautMFpseKB97fjxvd3oMDQsf/YEcLHk58tG2Fp0O/mlrXp7uXC10OH+lorGl3rGo21Jjzwdz18YsJw77lpOLWHJ7atK0aJed+vjYrsi6pkWfY+U1Bvh694xv+7Mg3nHhOPAXHt+/4ktXTHByqV9UYHQnz3LNiad51VUo+ccrX4fGyiIkcL5CFImf2BUwlzUGhetjYxSEigP4bGqgK9IqsO5bVG9rJboPP1x3mDA5FfUIn7v87Bi7/k4ZnvsvHG/FK5PX9tAe79MgvP/pSHl8S2PyoUpKYHIbDFmzoywQslOVW476scPPtDDp5eUu/aQm3WbMgVIlJntGNn6e7i6uggGopzy/DU9+J88yrl+i9z8+V6fp2rJbiHJ0bFe2Dnml147LtcPC2ueeaW5q5l4/sGygFFZm5o0d1MceD72QWwCzV88JQY2WBrxsR4WYf+yNcFaNiXfth6H6SG6rBwYR6eE8/kiW+ysKpk7+Id7qOHuc6IR3/IxeNfZuLdDQYZTtkESosfz1Hv75etJpgtDrz8k7inn4plpkRDu7qOrtJWUYlSg4J+cWrpSEeo3rUVf6wvl+tBPjr0ivSWGVxtgg+G2Re4lThzSNCK80icfRQztpU7pTjY7E4MTAo+rEV+ZIDpd92jlbgOaT2DkBqoB/nIPl56hAV7o09CkJwDmToP1QjV8PPUwc/PE0P6hOHqYyPho3edS5yzZ69QxAqjT7NFBPl7IT0xAOnhqgfpLYTK2+pEXGwApgwKha92nAudU4F/kA8GJrYWGWoMVWESQhfig97x/kgI9UJooDf6JgUggIpMxO/27xsGXxGnXmI9RGzrlxSIhCDVu/QTx1Xl1mJ5VgOmDA2X12szWJAhdLJfrwhMTPOX3oFvgDf6i5/2CdAjMdofQXsrqtZ5YEhaEPROHTzF74YH+2BAciBCfcXzFfeiiIzi4JQAtO3SnSSeSbi4NKe47vAwX1w+MQoBfl4Y2iMQvmLf0lqriCc94iL90DvOD2GB4n7FfoMT/aAT6cnT10eeVz4+ymyKeBokfpeK/gmH1YanP89HjfCQrz8+GuJy2oXSJpUyrc+plvNd09En9YK49xDZMpyLw5n9QaRNSo0Mc3CQF0GGqb6+HmVlZVid24hF+WrSuu/UNKTGhR62bl702xaLBRUVFfhoSTWuOzHdteXIsSSjHN5OAyYPTpCeU3c0wlUldbjz611I6B+Dx05skcnoAJPJDltHde1C2oL8O+kzVJxYsaIQry2rx50Xp2NMbHO/85aQaaW0aTKZ8OrsLORVmhEicgsXD/USGaoYKdjkYdM9smAz+wKXxTCHBDI4Leuye0c11+st3FIpB4sgA8b5w65LRFwInjw1HNnbyrAmf+9dnf73cxaufW9Hu8t1H+9E/X4O+3mkqCyolWI96fjUDsWaoLROJT9rc2qkWBPT0nUIDlKHINX6XLNYM/sKe9jMIYOSEglzQ0MDysvLsSG/HvOzFTnP7x3TeqJ3Yvhh8bLZw+48UAv1vHIzEqN9Wwwy0j4V1WaYOqpUFyRE+kLfGZ+h8LDLKi2IFtfXURzTu0Dpkqppnvl1J8rrrXJmu7MGeiM2NlZ611rVCcPsK5xamEMGGS8SKirmowZovSI85OAQVOr554Zy9rK7AToh0j1jaWzuvQttVLgvkqP8Olw6pVgTOg/EiOvbW4aMqog25NWiQog17Tk2SR0khSf4YA4UFmzmkEIegzYxCBmnkQmqUcosMaCgolEaMYbpymjedaPRgq+WFstW5jTWfmJYc8twbmjGHAgs2Mwhpa2X3TdKj+gAtTvRZ4sK5eARZMzYy2a6MpQx3byrFlZXkf/QeA/5PrB3zRwMLNjMIaetl00THBAVDVaU1BhkQxyG6apQ+ibv+rvlat/63hHkXatj7vMQpMzBwILNHBbIy9YmBukd5SW9bHKqP1tUBIvLy2aYrgala/Kul2VWwWJX0zhN8MHeNXMoYMFmDjlkkGhp9rIDm+qyS2ot2FFcJ70QLhZnuhJNddcmCxZuVWdfo7H1Y0LV6iH2rpmDhQWbOSyQUWrpZfeM8EYwjc4lmLuhoqkum2G6CiTY5F3P31SOOpMdNEDc8T0UWS1E4xOQd83duJiDgVMPc9gg0SYjRUWBQYEBODFN9aizK0zYmFfDXjbTZdC8axoPYGV2rQxLClYQGOAvS5m4zzVzKOAUxBxWWnrZMSE+EP8l/2RUyX7ZZORYtBl3R/Ouf19XhnqTA956YFJq8/SZXHfNHApYsJnDBhmoll42Dck4OVWEiW055SZsLqht1WKcjJ62kJDv66LtT59HE3HlB3QPLY9h3A8trhuMZizbqXrX1DI8NNCP666ZQwoPTcocdsiYUVFhbW0tSktL8eMmC0oagbhQHzxwerr0QMigUVL8b2s5/lhfDF9PD3juw2hZGpSInQ6nyBzocc2UNDXwCLJqZyWWZ1bAz3v/PSmD1YHYMD/cMb2PeA48trS7Qembps+cvaYQszdWyrnELxysR4/4SERFRTWlb45X5mBhwWYOO5TEqLiQxlWmMcY359fijx2qZ333KT3RKz5MeuFS2IXh+27pLtSanDhrTCI89V27ECintAG/rinCQyLjEujvwxNCuBmUtqmUqLSqAY/+uEOGDY/X4bj0AMTExCAkJESmba6/Zg4FnIqYww6JD9VlU9Gg2mLcE0khqiC9Pa8AJrNVGj3pqQhP/Ph0X/jBhG+XFsh9uioFFQb8tLIAl40Kgt1q4kZ4boiWGV2ZpXbjIgbG6GU65yFImUMNCzZzRCCjpdVlkzEb6hr9zGRzILO4vkmsaD+n04GRcU54W6sxc1FelxSxnSUN4t6ycUqaA946e9O9M+4DxRllMqvrTViwpVqGDY/TITLYV7YMpwwqxSnHK3OoYMFmjghktDQvm4xZj0hvJASphuzn1SUwW2xyH9pOou7n54sRcULEjBX4Zmk+rK5Ro7oCGYV1+GlZDmb0NCM80Mt1v80tidnAd35IrGmhng7/bKuEWaRPqrseIgRb8661+GSYQwULNnPEIONFdbRqv+xAjE1UPeeyehs25NVIb4W2k8ELDw9HWFgoRiUosNZVYNbqQti6gGjvLKnHrJW5OCnZgIgQfzkvMtVzcvGp+0HptdFoxsostWV4eoQOYUFqv2tuGc4cDliwmSNKy37Z8eG+cr5sYsEWtV82GTgSr+DgYERGRiIyIgLjk5wwVJfhhxXuXaddUGnA90tJrI2IDg+WLYgpY0IZGG5s5l6Qd631u260OOCjB45NQat+1wxzqGHBZo4YmhiROJFRIy/71D4KqPdWUa0F63LU0c92E22xjE9W4Gwol3Xa7khuWSO+XpSNE5NUsaZ7Iu+axdr90OquqavihvwGGZYWDgQKz5q8a4pP9q6ZwwELNnNEISNGxoy8bDJuEUF+iPRXt/23vVp62YS2T0tPe3SiON5Qjq8W58HucJ/i8R1F9fhmcRZOSDQgPjJI3g971u6L5l3P21QhvWsa1WxUUnPLcPaumcMFCzZzxCFxatlifKwwdiRX+VVm5Fc2NnnZVHzetnh8VALgEJ72LysL3aIh2o7ievyyIgfTUoyIi2Cxdnc077q2wYQ5mytlWN9Incx4at41xylzuGDBZo44ZMzIg9ZajKeEeyI2kIwh8OXiYjl4ChlFbb/WxeMRGCs87cbqMvy6ahcczs7b5SunrBE/Lc/hOusuhOZdbyyoEysiLYuwQbGqd92ypT/DHA5YsJmjAhm1ll72gBg1KVY2WFFZpw4iQnQk2sckK7DUluHbpflyv87GLtnALAcnJpmaxJrrrN0fykg2GC34ZXW5XB8Yo0N0iFq9w/HKHG5YsJmjAhm1lv2ye0d7IdxPB3KYv11e3DSTF+1Hgr1bnbYQ7THC01Ya1Tpt8nw6CzQoypf/ZWFKgqGpGJzF2v2h9Eje9ersGlhdbSgGCcFuWXfN8cocTliwmaMGGTfNyw4K8MfweDV8Z5kJBRWN0kBqQkyCrXUJaynaoxOEaDeUy2FMO0Od9vYiGhQlGycncwOzroRWd22yWPFvhjoMaXIIhHet1l1zv2vmSMCCzRw1yLhpXjZ5KWmR3vDSqwZvyQ61xTgZyrai3bZ4nFqPm2vL8dtRHlyFPOtfV6j9rGNcXbdYrLsGlAbJu16+owqVDTbQnDQnpHmIdBvAddfMEYMFmzmqkJEjMSNRCwn0w3E9VKO3PKsOpTXGprpsDdqfhHv3Om2nbIj2w4pdrj2PLHJQlGU5OJEbmHU5tEwjZSCXZtbIsOgAIMhfrbvWvGuGOdxwKmOOKiRiWlE3Gb+e4eK7Xt22cGul9Go0D5vQhG930Y7E+CQFjoYyzFx8ZAdXaRoUJbHZs+Y6666D5l1v3SUykXVW2TJ8Yg9906hmlH4Z5kjAgs0cdUjMmrzsIH8MdM3ktSG/HvUGc9NMXhqaYNOyW0O0BLGDqyHakRhchfpZf82DonRZNO+aJqf5dU0Z9eRCYggQG6JOUsN118yRhAWbOepoAkweM9Vlj0rwgJ8XYLQ6MXtd2W6CrUHHtFunLUTb3lCOn1fugtXeukj9UCIHRVmeg+k8KEqXhtJfcVUjKhvVUfgGxnjI0iCKZ667Zo4kLNhMp4DEV/OyaUzmnqFq+IZdDTCbLXsUbU3sW4r2OBpcpUYdEe1wDK5CxeA/LuNBUboylN6oZbjVasN3K0tkl8OoAB3So9RGkuxdM0caFmym09CyLntssieowXij2YF/Myo7FGyCDGZ7oj0hSYGl/tAPrlJQYcB3NChKsjooCv0e11l3TSjd5Vc0oqDKIteHxUGmT24ZzhwNWLCZToEmuuS1kPCFBvqiX5S67c8NlWgwmFv1y26Jdiwtbeu0x1I/7UZ1lq+OBH9/2FncPChKPBeDd2kovVHL8GWZ1XKdGkOmRrSuu2aYIwmnOKZTQV42eS/kxfSPUWc9sjsV2ce5bYvxtpAB1bz0tnXaiqFceMX5BzW4yvaievy4PBvTWgyKwp5110QrDq+oM2FVTp0MG5/sIRtFUnxr3jXHN3MkYcFmOg2aASTxI8GOD/VGYrBqEP/cWAlrm4FU2kMT7bbF49R63FhXgVmrdx3Q4CpZIsNADcxOpkFRIpqLwek6Way7Floaowzi4u3VoM4GNIVmWoTa2IwyhJTGGOZIw4LNdCpI9Mh7IcEl40jeMVFca0Fmcb2sU9wbdA4S7t3rtJ0w1JTjhxUFrj33Da3Oum0DMxbrrgt51xaLBWtyVe86XYh1aHDrluEc58yRhgWb6XSQIaQ6QhLEuDBf6d0QK7NqmyYF2ZOXrRnT3eu0IzE+kQZXUftp7ws0RebXi7MxNam1Z83F4F0Xzbv+b1sVGswOmf7GJekQIOJc8645zpmjAQs206nQBFDzsoMC/HBcT1WxNxY0yjpFEuy9QefoqE6bisepIdrXexlcZUdRPb51DYqSwIOidAtIrCl9Wa1WLBMZRCIhGAgOVNtVULxTumKYowGnPKbToQmh5mX3ihDejZfa+GzBloqmxmd78rI1OqrTpqJ2a0MFfpGDq+wu2jQoys8rcjCtxaAo7Fl3fShNUbVLUZVRTvJBMTw83lOmQ667Zo42LNhMp4SEloRRazHeI1RNqluLDLJucV+8bA06Fy1tRXt8ohMNNeX4ddUucb5m8c8rp0FRcmUDM62fNddZd320TCBVu3y6qEgOQxoXrENimDqgD2UgOe6ZowkLNtMpIaNIIkteDY0qNSZZeMrCTtYa7VibW7vXLl5t0c7XWrQj5eAq5rpyfOMaXIUamH27JAcnJrUWa/asuweUESypNjQNQ9o/SiczatokHxz3zNGEBZvptLT0smkglZQw1VjO2VgpJ2PQPKJ9QRNsLRPQ0tMemyjO01iO9+dn4QsaFIUn8uiWkFiTd71ip1p37auHHIZU864p7XD8M0cTFmymU6PVP5OX0y9KTa7kZZfXGqWXvb+Q0d2tIVqEEO0kHSI86nBqqrlpBDOus+4+aJm/2kYzFrvmvB6RoJONzXgYUqazwILNdFo0kdS87LRIL4T46uQkDHM2qY3P9qcuW0MT7ZbF49HR0ZiQ5o+E6HD5nQdF6T5oYk3paUNeLbQ2iL0iPGWGjTJ3lGYY5mjDqZDp1JBQauJKxnN4vBpOXbzIyybB3tdi8ZbQeckI03lDQkLkYCixsbGIiYlhse6GUBqirlwrs9WBUuICdYgM8W3lXXM6YI42LNhMp4eElbwcEtGeEd6uUGDLrubxxfdXtDUDrJ07KChICjWJN4t194PSUVZJI3ZVW2RXrimpuibvmhubMZ0FnTB0+++eMMwRhJIoGdSGhgaUlZXh90312F6pICrICw+eni4E1r9do0rHldeZ0WBSW/zuCafiFAeo33UeQqil2WbchSA/L0QLj3h/hZXSCC0mkwkfLsjFpl2NCPUFLhvhi7i4OISGhsrMGxeJM50BFmzGLaDBLMioVlVVIbuwDF9tcEp9vf74RAxNjdrNqGpF5c/9sg1mmwNe1CeM6bLQvOlXHZ+GPvFBUrT3VbgpjVBmsE5kBp/4KQsGqxNjkzwwuV+YbMtApS3sYTOdBRZsxi2gZEp1jHV1dSguKcVHK40wCsd5RI8gXHFcD1kXTYJNhpX21brovPDbDlw0NhahfuwhdVUozhutCl74Mw+Pnt0fMSF++yzalE5oIJ4FG4vx89oKOW74NaO8EC+8a6oi4QZnTGeCUyLjNmiNzwID/DE0Tp0rO6PYAIsQ8rb5Tk2waQQzi9kixZ48KfLUeek6C8Upxa2Pzo47pibisR+2YmdJvUwPe/NFtIwd9elfuE3tykUj6vn7+cl0xl25mM4Ge9iM26B5Q9XV1SgqKcOna6ywOIAzhkfhxGEJTYNb0H5kyI1GI177KxfnjYyU9ZtsgLsmmnBTvBuswPuLSnDxhBQMTgnbo6dNpo/EvrC8Fs/9niu7C57azxPDUtVR8KiFuFZqwzCdARZsxm2gpEpec2NjI0pLS/HThgbk1iiIDfHG/af1kq16yQun/VoKNhWJx0cENo0FzXQttNIUs9ksxbveouCzpaW4YHwyBiZ3LNq0Lx3z9eJ8LM+uR7CPDleM8pXF4dRbgBubMZ0NFmzGrSAjS43PKisrsS67En9st8PTQ4cnz05FeKhqZNsK9iXj45AYFcKTN3RRSLApXVDpiybaDUK03/23GDef2As9Y3ZviEZphParqKnHQ99nyrAJKXoc2yeUG5sxnRbOPjJuBRlQEmUqrkyN8EKgt05Ou/n3liop0u3lP4WpbjK8muHmpess5AVr86fTQkIbJLzlGybF48Xfd6C0xrRbutAydTmlja4QoEe4XqYrLolhOiss2IxbQYaUDDK13vX390N6hGpYF2fWwWi2Sm+L6V5owq01SmwWbeCsEdHIKqmT3rSWNkisaaFi9JXZ6kQfEf46RIf4NI1sxnXXTGeEBZtxK8iIkjElL0j1svUy3OZQUFJjlIa5PS+b6dq0FG3KzGmiDThgE540pYuW0HpNowUZxUa5Tn2vqXW41nCRxZrpjLBgM26HZpjJKCeGe8PfSw1fl1vfYbE40/VpKdokvFR1IkLhdKh13ORha941ra/LrYXI58FLWMHEUE+ZAaRjWKyZzgoLNuOWULEleVIBwsgOj1e97KU762CycLF4d4bEljxkrV7bQ6xT9q1lJo7SBxWHbysyyPUwfx2CA5qL0lmwmc4KCzbjlpBRJW+IjGzPcFWwqfHZ9qIGLhZnZPqQS5sx4TUPu8FkRW6lWYaNT1an0eTicKazw4LNuB2aMdaKxSODfeCjajZ2FBuk98SCvS84YbHufWKU9rDbzDAYVMFzJyhdULXJ0h3VcIgMXoA3kBympiOtsRnDdFY4dTJuiSbYsrW4ny+GuorFM0pUwe7MxeJ2qwmlpeUoL6+Ezd66MVR7VFdVyFnKGmjw9EOGgln3DISvjzfe+2+XK2zfueOcsQhMHooG17o7QGJN6YJGN9tQoF55bKCHrLumdETpiWE6MyzYjNtCoq31yR4Wr4OHToibwY68is7dWvyHNx9GXFwMEmOicOJNb8De4WUqyP39UURERiM2NhYnnfGsK/zQoFjUT5vtADM3bthUgATbbLHKdEL0iWrue83F4UxnhwWbcVvIuJKRlV62r68cLINYk1vfqQW7rLZUfpLe/fvhfViUUy/X2+Iw12LsxS+61gRcyn9QaMXhG/LrYRW5JKpG6RWlNl6k4nAWa6azw4LNuC1asbjW+Cw+SDW4+VVmWezZWQVbI6F/srh+G76c+ZUrpDWl2xaiutGCQWOGI8QVxhw4lB6oT/bcLdVyvWe4B/xEuqG0w3XXjDvAqZRxa7RicTK6g+PUDtmVDTY0GC2dvrX4XW99gZ4BXvhx5h+oaVuVrVgw895HZHH5o3ffijpXcEsclgb88t7TuOriczBlyvE48eTTcPMdD+C/bUVtnHEFRZsX4LYbr8CJJxyPk087B0+9/CMsXu2XaWf8PQt33HgVTjz+eBx/4jTccNt9WLqj2LXVPaF0QOmhusGMWqP6sFPCPGS6ofTDxeGMO8CCzbg1mpctPexQT1ksbhc6tCavodP3x1b8B2LkwL5ozPoT7/yV5QpVqc1ehvsXZABRJ+G4wVGu0GYUuwH3XnkGzrrxEXz61wrU1NWjKGcT3vnf85g8JA1/bGxuSFaRvQbpI0/CG+99jh0FZcjbugKP3nMeLnh1BxDk2snF2p9fQ/+pZ+Ddz78XwmaGoaoQX77zIiaMPwGrytVRwdwRTbBLa5rvITnMW6YbSj8s1ow7wILNuD1kcKnRkBTtIDVJr8zVund1XtG22c149sGL5fcfXrpFfmp88/038vOpme81jeTWkvXfP4dXv1mI0Pg01JfkYd2aNdiamYcvnr5ciLkFpw19AHVUuqDY8eV9o2GyOnDmwx8iP3Mrtmfn4ZenT1VP1KKZt6LYcMOdj1EuCL9tLMGqFcuwcu1m/PLCJUB1Bs475lk4OnGJxZ4gwab667V56mApsYE6hAV6y3TDrcMZd4EFm3FryDOihRoNkWAnhKpJ2mhxotFkheJUOnVbrZ4nXY8pacDmFTuw0+oKtJTg25e+RGBkD9wyKckV2Jp3vl0gP+/+4l8EenvK78QFNz/u+vYVVmXWwF6Xi0d/UkOeuOlC9Qs8cfoDv+D5s8QPt8CY+T3W5TfgjOtfw4npza73Cbc8hUHi02D5BlYay9PNILGm0haT2YYthapgD4xVS2W04nCGcQc4pTJujybY5C31DPeWYTQZSK2Bhint5KOeeYbirOnnwWnJw9VPzpUtx1d98yYW1ZoRf+JdCPZu3/urrCwTf9NwzvjEVmN5eYXE4bH+6veKBhMaq8qhStR0JEUGyG+ETohUnwT1WWkUrFwmf3/xn29ixvTpmO5aTjvjWlC7doPZDhvVN7ghVByeX2mATWTgiPgQtQ+/1jqci8QZd4AFm+kSkJdEgh0e6IkwP3X86C3FFjiFoRaKre7USTnvmsvk5+o3zkeVwYYXPyeXOAxvv3CV7FveHjqdeHUjgxHWtrichKdC/eonFqdVc9tJmFxfO8DpUPsm+3kHwkd4nyRotHj5BOKYM87AuWfMgK+n+5kMqhYhwc6rMMl1eg5hgT5cHM64HSzYjNtD3hEJNhVvksD0ck25uaHQLAy1HU4h2J3Zy44cPAV3HucPs/CIf/7lCyz/NxP9ps7ACYn+rj12R1FERqSyCBlVqshqKNZGzNEE298XvsFah7DtMFpaNEUXj8PcZmRR3zB13yln3Iaffv4Zv/zyS6vl8w/ehrcbCjZB9de5lepIMSmhHgj0ExkRbh3OuBks2EyXgYo3SbCTQlUDbBJaZjDTtIpt+0x1Nnxx4U1PiE8rbrj0GlAHqrGX3Cq3dMSo5N7ibzluO/MdkSFRw4ic/+Zglfx2Aob3CoNfZCKOkeuZ+HdzgfxGWEpW465PM11rKj3Hn4xQ8fnNrO+g9lTuGjgc6nCkeVWqYI9I5MFSGPeEBZvpEmheNhVzRgQ21802kGA7Ov/sXQMnn+H6JogYiyfOHe5aaZ8bH78O4eJz46p7ccIpp+PDL77APTdfjePPvUSEeuLlX19FtLfwHn0i8ehbamOza86ejtvueRb333YqeiSMQbEvFZo34xF9PM4a3x/WnXPRe+A4vPTmZ5j95yw8f/stmDRuBCbe/mOnbsDXHhTvVCSeXW6R3f3k3Nchaq8CFmzG3WDBZroEZHipPpKKOUMDvOHrajjtEEmcPKzOJNgBHmqGwtenuXW3b2QPfHmFKtKX3HwTkvya61Y9dOp+ihBijfC+Z2Pu7C8wcWAy/p3zG667/HK8/M4naIgchjtf/wP/dyq16yY8cPxV7+GWS0+FrmI73nj5Ibzwxnz0PeMK/PHKtXIPfYuK8vfn/Ik7zz8FHltX4N7/uxIzTjkDD7z+NoosPpg4grx6FVmHLv539iZoFO8Oux07y9X66wBvnRRrbh3OuCM6kaDdLdPMMO1CDYtMJhPKy8vx85pKbKugolAL7pwah9494uUkD52iztLpgMXigLevt7gWV5iAXkWzyQoff5/dctJ2iwWKpw+82raREt5jbVU5quuN8A0IQXxMhGvD7hjrqlFWWYeAsChEhwfKMLM4r6+Pj/zeEpo+s7S4DFRDHhoRjdDA1t44lVpYnE74CeHrbEiRFtdnNpuxNKMUBoMRG4osKKx1IDXMAxePi0JUVJRMD9zojHEnOIvJdBlIiLV67H7RqiH28vSG1WaXBrzT5E099PDxay3WBF2/XztiTXiKe9pNrAnh6YZGxiI1NXWPYk34h4SjZ1rPJrEm2hNrwtPLF4kpKeghlrZiTXgIoeuMYt0Sim+KcmpwVmtUywJSI724OJxxW1iwmS4DGWDyoMkYhwfooBf2WOehQ0UjNTxzz/7DzMGhiHi3WO0wWNXMWq9Itb8+tw5n3BEWbKZLQYaY6if9fLybPNLKxk7mYTNHBFk07nSgqE7EvVinceYDfdV2Dlx/zbgjnGqZLgN5TLSQh+3r4yXnOyZqTerAGSzY3QuKb6prL2lQS1fC/dUGZ1RvraUVhnEnWLCZLgUZYTLI3sKLig5QBZoEm+oxWbC7DxTX0sN22FFnUYWZBJu8a66/ZtwVFmymy6HVY8cHq8m73qx62FyP3b2g+G4Z59EBXBzOuDeccpkuBXlOmmAnBKthDRZFthTXvC6m60PxTGJNffA1bzoqyLNJsNnDZtwRFmymy0HGmAQ72IdaigsvS2h0ab2dPexuBsW3VQg2TWdG8hwR6MnF4Yxbw4LNdCnIGNNC9diyLtuVwguqLFws3o1Q668dqDIoQqx1CPEFfL3UNMFF4oy7wimX6XKQYJNRlg2MPNQi8DqzQxpwgovFuz4tBZugBmfkXWtizV42446wYDNdDk2wyZvSZoOsM6kNkFisuz4Ux5pg11pcgu2ntmugNMFizbgrPJY40+UgQ200GlFUVIRPllWh0qRHmJ8OJ/YPRWBwsDTcwmq79ma6GjQ7l9ViRU11FX7fYoQTOhyfpsfkQfGIiIiQQ9eyaDPuCAs20+UgwaZJQIqLi/Htygrk1QtPW+dAz1DAPzBYeFkk2K6dma6HsGg2mwX19XXIb1DHSp/R1xPjByQiPDxcVpWwYDPuCAs20+Wgom8S7NLSUvy5vgzryzwQIuz21eOCEBoSIj0sputC8U8zdRWUVOHTtVYZdtZAb4zul4jQ0FA52hnDuCMs2EyXg5I0GezKykrMX1+EJbuAAC8h2KN9ERYWJg02e1hdF02w80tq8OUGmwy7cJg/hvdJQIjIsMkqEYZxQ1iwmS4HJWmbzYaamhrM31CMhVkWBHrrcOOEEISHh3EdZhdHE+ysQuFhr2qUYVeMCcagtDgEBQWxYDNuCws20+WgJC1bCNfWYu76YizINCLY1wO3HR+NiIhwKdjcF7frQoJNjQ53FFTggyXVMuyaY8IwoGcsAgMDZUtxhnFHWLCZLocm2A0NDZi9tggLdzQiRAj2HVNjERkZyYLdxdEaHWbkleG9RZUy7LoJ4egvBDsgIIAFm3Fb2GoxXRYp3DQuqcBDJ3KnOnUUNF667kLQ5+5+SPN2hnFXWLCZLolmsO0uwaZuXGywuxeUSdPgAWmZrgALNtNlae1hN3tfTNeH4tmjhWI7RTrY3etmGPeCBZvp0pismmCzWHc3PFsItt3BYs24PyzYTJeFPCqTTTXUfl6t6zmZrg3Fs7e+Oa5t7GEzXQAWbKZLQsZZ9se1q0Y61M+DZ2rqJmgZM29t5heBTaQDShMs2ow7w4LNdDk0wywF26Y2N6JuXSTYLNbdA4pnT+FhU8kK0WBlsWbcHxZspkuiCbbFJdhh/nrue90N0DJk9EnxTSUrRJ3R0ZSRYxh3hS0Y0yUhw0wDaGhF4ppgs4fd9aE41gQ7wl81cTVGu8zAsWgz7gwLNtMlIaNscwgPWxPsQC4S705ogh0VqI5qVm2wywwcizXjzrBgM10S8qbyKtWpFf29dPDVs2B3JzTBjgtRBbvG6IRdZOAYxp1hwWa6HCTW5E3lVJrlOk38QeNHkwEnWLS7PhTHFOfBPjoa5E6OeFdncsi0wTDuCgv2YUAROfkGow0Gk715aMwjgKI4sHmXEe4xRoQCi0U8H9favmKz2rE2u1HcY/s3qRV5kmHOr1I97BBfnZxSkT3s7gHFsSbY3l6e0LusXEW9pakem9k3bFaHsGV2GC0is3MEn1tNtQk5rvfXnckrakSta/CmQ8FRFWyrzYFGs8O1tn/QsdXU8tO13jlQYDMZcfv7Gbjm3R246p3tuGd+vWvb4UURhujrzzLwzI+5yGoQXoR4uczi2RrE0pxnUGAVL6Aatg9PTuxjFJkO02HIdNSX1OGyt7bj4i9L9yuDsS2nEi/+moffciwdxj0ZZKvNLj0qItSvWbCZ7gEJNsW3j5e+SbDLG6xNgn2oRdsm7FGV4QDskbgOixBDg6s3Q+dBweZNJbjkTbJl23HlWxlYUWhzbTu8OOxWPP91Nt75t0wNIDskbJbWRVNFgUk8N5N1356bImxYvYj/jjL6BwqlI4PZDlt7RsxuxDPf5+HRb/MO2Vj2R9WCffpTDl78t8K1tn9892smnv2ryrXWOVDsDtzxcS5KHV54+KI0vHJZKm4ZE+DaenjZsK4Qv1UDt5yTht7BarT++9dOXPV2BtaXqjlVq8GCG9/JwFVfFMKyL+nWbsa94mX9s3B//eC9Y3c1BoPwmPeHQenRuCzdE9/+mo0t5bsbEHqBqDjcIs6rvURRgV7sYXdDKL59vb2aRjyralQbnh0Ofv9jJx78tfwABNuJJ97NwAfrG1wBnQNbTR1e/LsKycmh+N+V6Xjugh4YGO3p2nr4IMfj6a9ykAc/3DsjQQvFE59tx/VfFkB746uySnGtsG3vLq91heyZqvJqXP9BJoqN+x1De8RUZxI2djt2VLeTmfH0x8MzYlBWYcDjiw6N43bQgu2w2bBhRzVW7ahFjfB421JVacDKrdVYLbbnV1hkmKHBjIIyIxosThiMdhSWG1FQakRx3d6Mt4KaKhN2if3rzMKbbbRilzgPnavSoB5Lg/wXlBhgEDmvirJGLBW/XdzQfF0OIar5hQ1YJcLX5TSgsUUOzdBgQUGlRRa7rt9Rg5WZ9RCZuFZUVxqxOkO9n7xycwvvlYqPnKgXQnTGlHgMivNDYpQ/0kKbE3ljvQmrt1Vjzc66Vjlqp8WK3GIj7CIflpVTi+UZNTC7TtzYaEFJrQ052TXYuMsEh8WGtWJ7qbH5eHNtI977rx7xaVEYm+Ar6+yEMmHyST3gL37+o3klMAgh+29pERrF/Tx0Zjz8Wk5l1AYSvSJ6riK+aGTPcvHM6RnTc60XcUbUieewSyRSu9kV/+JZaRNtEBYRvoPuRTznjEIDWj7GKnG+Rm8fPHlWEl44JwYtRpAU51OfhUN4yFsya0S6qpPXo+Eh3KUTT05FsLe4r0Xlrc6rQV6UxSquTRPsIE8p2CzW3QetSNzLyxMJroZnlQ2qYHdUj11TLWyVeD835jW6Qpohu5KdV4fltD27HpVC/Im6GtUe1ZiccBhtTfaovH7v3miNOLag3CTedaC2XtgyaQcNKKOXVGAU9ii/QtgYhxMZWTVYuq1G2Kvmd4FsWd6uennNG3IbYG3xnlSK97NYnKfOdU/bS9X2HC2pJtu8pbVt1qgoMojz6XDVKQmIC/dBakIggn1cciF+Z1dRvfpuFxlbeY9V1SaU1lphE7qwWmxfm6e9+wqKy8Q5xTWv316NQmHTDLVGLN4qbJ2WeReU55RhR6UdV50Uh2jt93QeuH5COMw1jXj332r5PF6cXwP/iEBcc0y4uk8HOIQdyCsRz6LGKjNTxZWqLdtVZlJ3cFFZbpBasXWXEbsVdog0k5kr4l5s3ySec72MAydKRXwVVanPtaxS1bR8sbQsyE9Jj8AVA32xY3UB8vaqb3tHJ4xh89PaT0pLavHo14Ww+nnCV9xUjSIe7Ok9MTlFFY05f+fis40GhAmDSU+h1uGLz/4vFctn78CnO+2wCoNKP+7jstihvWPxxvQI+b1dRG70hc8ysbXOIb0neq7asceMjsX14yNgNplx07tZSEvyxaYCMwLET5OWP3ZlH/QP98KsnzPwda4DkeKa6sVL5xPkg2cv6yUShw4Lf8vB+7us6OFpR4nNA1YhTunpkXj8tFjoxUu+4L8CfLiuESEBeujF79Pzf/vGfgjRObCjyASrSBwv/lGMY8bE4LhEX3l9cbGBCBfnXr6qEP9bXAs/X70sqlY8vXDvOT0wIsEHVTt34abfGtAvwhM7RWJXRAp3+Prh3Wt7Yo047tuNJhiEABIpoV7IF4k9NNgfb13dE15CeJcuK8Rbqxvx1q19EdEmC5a7YRceXlCHEQNCRMapDn0HxOHRkyOwpyn8qfjong8yUC4siZZhkc9ZJJVzZvTCaek++OrtrZgfFIBIswklItdK4tivfwwenhYFT7sFt76+E+XimChx7xUicxGfEIpXLkiUOcQ3vs/E2lIbzJQb8A3B1zcnNV3Prm0FuHtOg+w/S5kp6pYVEBGMty9Jgp+nJrgKti7OxZOrjLj/in4YFtF8N2SQTSYT1meV49Ol5aDRKe+YHCbiIQaBgYHSiLNwd33IrFmtViGKNVi8rQxzMkyy8eEDM1IQFhYmhNyrKR3QvotXFuKDpXUIFnbBIITdHOiHty7rgSg/PSxGC16emYVNwgmOCtLDaHIgJjEKz54djXe+3YmVpUKg2tijoQMjcecJMfJ7R3zx/Xb8XewQ75hqgtVjFSQPT8bTE4Ox7O8CvJ1lxvBgB1aVOsU7oiAqNgjPX5QCP2ELn/s4ExuEMxIh7quKnCUPb7x+fRpi/YFX38zAmgBf6OvM0AsbYRLv0ZknpeL8gf7SNs9dmItP1u9um5VGM3KrbCjJrMQHm4y49oxkxItdnEK8eyUFQC+E+NPZeViQZ0W4eEerxbsdHR2MFy9NFj4x8OaPmchu1MFeZYFBXJdJ2JDRI+Nw54Rg3Pa/HQgK8cDOOifCQkQGWhjQanHMqSem4JJBQeJH7Hjy9e3IDgzC+9ekwLfNa/rFT5mYW6rgokHe+GK1Abec2wvHJvu6trZP2Y5y3PVnhYhrkR7EIyJ7Sb6Kp783PrkuXeyh4K8F+fh0QyNihW0tF7Y1KSkYD56RhFBvHZzCvt3xSS4qha2KEGmhXjiY46am4freCm56OwcNIurI5xNmBeKOxNl0eOjG/ujro/4+0VhjwNXiHMdNTsGNw8V9HgT6xwWu7/uHELBPv81Gia8v3r4mHWeOC8OuLVVYlGvAKUPDxANy4PM/ShAnvL6XLuqBGaOjcOaYUHiLG+rZOxJnjo1GTX4dvJLD8cYlPeX6tHSR0vaEeMEmDFOPNe6qgjkkCu8I0TpLrI9MUo91OOz4c001yoSI3Hh2Gq4dH44/1lXDEugvvc+wUF+cPyUJp4+KxKREPX5bV4sav0CMjfdGofBiV5VaEJcchtcvS0VIZT3m7zRi3MgoBFFiml2CtIGxeOX8FHk/dA7qMmSrrcPDvxRhZXajfDGKRO5tTZbIgQqv0x4Xhv5eBjzxcxn6943EKxf3xDmjgrBsfRXWVzpw0sBg4SE3YPZ2Ifhe3nju6t6Y1sMDczfVIjUlBKg3YHm+Gfde0w/ZGZWo9gzAXRNDsKLAiOnDI+SMRAtWFaPe0wdni+felrDYEOTlivvKNSIg2Bf/O18VzT1BhuxEcc9njgwWhqwap5zbFw+dFCviOBp9RKaC2LGxAptqbEjuFYFXLu2J6Lo6/LWtHuOHRCLE2wOpcQG4cVoipo+KQpLDgvnb6zFsZDRIW8cMiBBpIRJVmyqQp/PH2aOCm66pXjzzeTvNCBEC//qVaejjbcI/GQ0YMzACYcIAqOgQLeJr/spaePj7YbjInGlI79piwTxx7hLh5SQG6zE8JQBBQUHw9hapT9wbC3b3gNICibaH3YjVIiNOmb9xqUEI8BdC1iLjZhIi9fRvJRg/LgGPCUM9uY8vZq+qQmOAP0bH+6CkoB5fbmrEgyLTf9WEaJw+NgqT+wfKNDtapEuyR7oS4TV6huGjG1KlPRqXGijPvSeGDBC2bHQENq2sRPqxyXjx7CR5ruNTVGtfIuzjUvGeW/1E5v263hjua8Nvm+uRIN65lAAPxIR647KpCThjTDQm9/DEX5trES3EJj3ME2vWVaJAeNgXntoT902PRq6wzVvKbDh5SKi4bzu++L0E0T0j8fLFrW1z/o5ivDS/EhtEJoQc3wzhUa7cWY8VwpYNEu/tzq2l+HazETec2xu3nBCL/oEOzBG/Wyzs0rgEb6zKqMK2EitSyC4Iu24srMe/uWbxG6FYtqIKuU5PPDQlHPO2NSK5XwzSDSY0CE95vHiHTfVmfLi2BidNTsCIaG/5DFqSHuuFv9bUYG2xDemD43Dl8GDXlo4JjAzAWcJuTUr1xByR43rh+v64YmIMTh+hOobG0ko8Lrz1KZOS8PCMBBwfD3wvbJ5NOExDRdzX55Xgmy3C/l4s4p6OGxOFEVFCmvXeOEXE1cn9AjFrfQ0evqQ3rp8SJ+I+CpGqiWzC20ePjFWVWF2u4IyRIXt0lvbG3mx3h1iFyCwVOc7whGBsz67D2h0GxMT5olF4parPTuP4igjPqsTzfxZLL0u8IvLY1qi5y0PN1af0wLEiEfj6e2FGzwD0pJykICYuEJWFtSLiy7FOvAyUK6aibA2/qCA8cpqINXGtE10Jgh6STggjveCZW8rw9K+FKBW5cBqrmPAKD8U71/eVIk+lOOecnCzX3xXLBSmeyNtUBYM4y4VajtvLD6em+aOszIzmghkPPHpxKuKEKIVFh2JcT39EubKYCTGBGBZI33Xi5YwQOerWKcJmURAkctMdkUjl4oKAJsHbV7S4aT+OfGLD8eBJMTJnOWpUNMYKYfSlZ+KhR2/xfdO2CsxbXYbcarWQqG032PZSg4onHhVxQDn2lCQ1E7LblYtnGBUA2FuUX5GnRIvNbseWEvXJJoZRsahXk4Fmse4+UB02xb2/MJgBwlsidpQYZRppSVVBJUwiGcX7KMKO1SCnwg5KdRlFanGntyzZUfDSl5n4eR0V4eraNboHlrL2/I7pg/zwmsjk+wr706t/OI5L8YfQY/FjOvROC0F5cR3mrirDmlyTPEPL0v7EIQmY0YscGS8MFJ/N1ydss9DD7TlVeHZ2ESoMzbY5bUCStFtPTBLOAtmk61Q79s4NfdBL2KCsnAZEhPpjYpIw7oIBg6IxWvzE5s110pYSfdLCxfsbB724xpOGhWKs8IK153Xu9BRE0qFC8O48ORIt8zVOyiEI+kar526Lv3C2tDKLNOF87R9tjI9EwZIVdeJTh74hatwXKt6IFYantl6tIvAOVDMOr36fIzIZ9QdmQ0Q6PDZJHGNx7HevmLYcsGAr4vfp8RbvqMJPK8rlslUk9LQQKmqiPfS46YI0nDkgAOszqnHLu9twz8wC1LmKWA83Ab5qEtEJ8bjwzJ44rV8AHAYj7v1oO+7+qRCrchqxUbyQbV8TL3HxlNAIR4uno/P0xLtXpOL8QYHIyanFbR9sx10zc1EnMigUgV6eHk0CTg+H1mmhc6kT6Ysw+akSTAZEXGLzT3g0GRVvXy/831mp6B2t5rS9tGauAk/XtTWjwEoJve2NuDCXVWNOngkRAXqUlxvx9kaDa8vBExJIXWbU6wmMDMUd5/SUmYzS/Brc/E4GnplTgXW7DNheoRbnt73yPdF0n7vdr4aIJ/HbInvoWlchr6qm0ao+E0GMMDKaYDPdB82wqvXYXgh2ZX53lJlgFxk6LXNHKK7X6991FcKOVeBH4fGGRXojierTBDHJIXj2rCQMj9Tju3+KcM3b2/D2gkpxvNx8WPH1Ftfvsis6X3/ceE4qBoXrhZNhxcMfbMN9PxZjZb4BmwpVwW6Jf4tGlq3lSo8bz0/D2QMDsXF7DW55bxvunpkvbTM5JmS3xNOTe3qIh0PrNPMZnUuc0nVOdbtYQTDpq9A1V4jIDHjIYmciLj0Kd5yWSJsloVo5t/gQuzUdQzR1ge3guc5dVII88Xt9QnX46698bK7cezuBvaGXkajg52Vq3H+7qBze/t6IdMW9b0wMHjs9Hr0DFHw8pwAXvZGBzzbu3sZhb/iRJ6ej+Q1cAQdIsxLsJ3qRkMgD6j84Fk9d3hvPupYnLuopIkuNhrAwP5x3Ug988399ccvIQBSU1WNNSfNDJu02uxox7Y6C/O0V+OKfYmwub78/nsMp8isdvTTthFeJ3HW+SJXXXtQHj56XiptOisVeCuFb4RfshzNPSMGHt/bFTePCUFhmQJbwtPeGjx+JhQOZJc0NO9ZVWOXLePAyohPn0aHR1LrRCGG32vHk9yWw+vni0ct6YVyUHosX5KGgRSO8vUF71hs62L+DZ7+juBF1wkt+/47+uF9kPC4dvYeiqwNNgQ4zqgwK/P2aSxvIAFMddlVD87MID/SSBptbiHc/KL41wY7wU+O+tN4mBbtlwzNvP+FkiM8LTunZZMdouW+Kq0GTzgNpPUNw58V98OE1qRgp3qO1OTViQ+sXwOmkoU9dK61w4t9VpZi5tLyplXNLyII0ttNgV9LBO2YxNCK3wYnrz07Do+em4saprRtv7o1QYZvPPTFF2uZbhW3eVdaAVcV77/fsJVTWYKHuceqFWRtM2FhPQ/+2qLTdF9q5Ly9XG5XMqt1talVhFb5f24D03hF49OKeCPJ04rN/2n+e7aH9HE2z2pKgYPKaPHHD6amt4v7iMWrJHqWh/r3C8ciVffHO5T3RS+/AnIXlMLW5foOrHUK7KE6RqXJAH+AlS2APhgM+3DMgAKf38MamDUX4+L8KrM6qw7/rhae9skpNtHYzPv5zF+ZvppaCjcgqE4lBJHxqqKARKr7nZ1XjQ5GrWbqlEr9ltPD+ROJ/568yzF5XjT8308vRGj8hgsUlNfhpQzX+21iJlXl79xz1rqn25ouc1JJN5bjvy3wYZYhKR4+cwm1mG179LR/zN1VhTbZ4WSrNMjKDvfb+CBMGRyNF5Cy//DMfC7bV4td52VhQaMWUoWFNOc+OoN/eQ1KQ9EgMQFmNRTaCa0JEwrrVu5BtVXDp1HjE+nvh4pPipai9Or8clhYtujtExFeweA8Xzs/Bwi01mCeMzlaXt7yno731HrJ15uyNwrtfvAtPzKemJdoxCpaJ+Pp7QyVyqNS60YD56yuxdlfLmNjbPSso2FKBSmFz+/dsznJpgl1SpxoeKpiICPTmFuLdGMqoUduF5DC1mJXGfaAWzC0FOzw2AjHCNrzyfQ5mb6jB6sxa/LW8GNtdVTn5+dX4+J9SLMqoxRaRTisbHfDxbs4oEn7+etTX1OGb1ZVYtKkSizNbdNOyGPDl4kr8vqIci8vbCLNIl1GBOmxZW4xvhWf/34YK/JWtFsXv6R3Q6fTSeK/KEPZvXSlu+zRfjmegHbPH90fY5k9mq7Z5HdlmcojEux4R0NKWqWdoe57h/cNhNFhx94+FWC688+d/2YUaTz3+7+SIvYoJ3XnL89H3lu6af7A34sVJ/lpZLRtyNaE48DrZLB9v6WR5+vrhonR/FBbU4NsN+9YdTq/3lNf34bwiLN1Wjd9XlYs1HUaMjUKwpx0vf5eNf7fXYdX2WvyyqAhbKlRjumtjIWYuKcMSEb51lwHlImrCInyhtX+lXiuUsl79eRcWbq3Bn+K8baPY3GjFMuFDjBkSItyYg2Nvz3gP6HDmmam4IN0PSzdW4K0/i/DpkkpkuW6UBCMrvwEzRUJ/a04x/i1z4sFL0jAsvNmnvOD0Hjg5xRdLhPH+QORaVpe0yOF56HH2QF/4CkEckrx7y7qzRO5wXIQevy8uxSf/lSOj6VidLH5orwQ0IiUCN48IRGlBLT78txJDhsdgTJgHAl1T8Pn6esC3RRZIJxKxLN4R30kMdhQaMPPfMrw7rxhLiu24/cLeSA9pjgIqTqLf9mlqzazhg6cu7oEeInf2xd9F+GW7BWdPTcFlo0LlVi/5O+3X8FNxOD0Dgq7NU3jTHuL8fl7N+4/rGwIPIZB3/0bFdOorYak34p11JvhFhGBKmipqUTHBuKWXF2qLhFHah9w09D6474IeCBc/9PnCEnwlXqQSg/omeYvMVstn1ZJxw6NwXIwn5i0uwbfrG3DhcVHy/qgIjF7Rv1ZWYKYwYGWedN92fLukHP/mqBkuysHTvlqRmng0Mg60agrCYXPg2SUNCIkPx+gWLTzo3sl7yixRxb9nmDrSFQt296Slh50qK04Bo1CCBpMq2Nq7QlVQr9/QEwOFmfl+UQne+kuI55pa2XWUoJKqxVuEaM8vxvvCTtmCAvCS8LZapqmTpvTAxGi9cAbK8fG/5dhY2KLEyycQg8T7EBziiwlin1YI4b3zur4YHuGFOSvL8cmiCmx1eZiePmRP2k+3ASHBOK+PHzJ21uKTJdUYPToGQWS/pO3RIUDYNJ8WTq+neNd81RdQtc0Fqm1+U9jmf0qduP+iVAwPb36XvHw9xXvn6Xpnm0nvHYVXT41GQ3kD3ptXggKzHg9cnI6eVNwq8BG/Q8vu6OAvTkamzNNHLzI4ql31FtcZoBUN6L1w55RA2KpqsTi3uXVPTWYxChoVnHxMDOJlNOpw/LSe4nr1WLx538biCBN28KHjwlBZ0ogP/i7F7K2q0OsDgvDyecmIFtmJT+cV4m1h22dtqYfR1TbGbLFj/roqKfQfC5sV1TMUb1wcJ0Wa8A3yxYdXJCJKZ8XnC0rwnbCRjS3dfvGsN2wqkV/PkO0JDo6D6talIrwa4a0pilq/oRWHS8SpqaERdd6i+sb2jSZ5ReJCxCba3nYXh8g26jso66FLlxllsVmrS9079Ht0ReoE9/uLQ9wQPTCql251r/sAXS89K2lI9vl69wUFS5fl443ljbj7st4YFbU3v33/0J4ziee+3rN2rwfynPbGkrk78dYWC+6+qDdGxqn3Sr9HnlOl8HIe+ylHjmh05kAfDEuLQkREhMiM+XaQ/piuikyDwrg0NjairKwMHy+rRaVRwaTeQTh7XAr8/PykoDejdk+kdELptmVq0dIzGShpy1zhLdHek/bsEXWVpE0dv/d0rfL08rf3FbJH2jXtF/J+6Ff3ZJs7hu6H3rFD/X4rTgfu/CgT1TYvvHpjr926qR4sVJQv7be45paXrcWvjHsR3vJ5yLgT2yliO9QiuY/Yo42NLC+owd0/FCFpSAKemhImz30wHALBZjoDNosNb83MxAqjJ16+Jh1JrlKD9nHgwx/zUdpBvYvOwwt3n52M/W5UfgTIzq3Egz+X4pQTknHJkObuYJSMqTvX6sxSfLq4VNbnXT3aD6nJcQgNDZVeFgt290Prl19RUYFZ66uwqcSOQB8PPH52OoKDgqRgc7roXNRX1OPhbwsQnBqBp0+Jc4W2T0lBHT5YXtlhUfHIodGY1ufg+j4fMA4LHvgoC/W+gfjf5SlNXvnBcOD9sJlOhd5TjzFDw+Ht64NRSX7tegAtqW6wITjQC1HB3rst4cG+GJDkf9C5wcNBoI8eZp0PLhkd1tTIRvVs1D63S7ZXoqDKAl8vHSakBSA0JBg+Pj5tPCmmO0Hpg9JGbYMRWVUOOWDTmNRgBLXpj810DnwCfDAwygux8UFIalHl2B400VKFSUF86O52jJbkmADEurr0HnE8PBEg7NB5J8SjVfOAg4A9bMbtoSRMnlRDQwNe/ysPBdUW9I70wHmjIhEVFQV/f38W7G4KpQ2qKqmrq0Nmfhk+Xql2yblpchwG9IyWmTlqmMYw7gCnVKZLQB42jR9eVKM2phuW4CWNMTc4Y7QBVCICvRDiaoi1tcjQ1B+bYdwFFmzG7dE87A0FDbIhDHXNjgvWNxWFs2B3byj+KePm4+ONfjFq8ei6fIPwvFv3x2aYzg4LNuPWkFjTQt4S9SklqK8/tQrXBkxhui8k1s2C7YMeYWp6aLA4UFxjkoLNXjbjLrA1Y9wercFZWb1aHJ4ijLJWHM4jnDEU/9oAKhFBzV0ec8uNuw1TyjCdGRZsxq0hQ0vF4ZUNFjSY1SGGBsRy/TXTDKUBqhqhEpcgP29EB6hpYntJs2AzjDvAgs24NeRdk9H9fX2FXI8L0iHEXxVsbhnOaGjF4lRVMr6HWo+dVW6CyWKTGT6GcQdYsBm3RSvKpIlPtpeo4y/3DGuuv2bvmtHQBJsyckmheviIvJzNoWBDfr0UbPayGXeABZtxa8jYlteaXEMHAinhXlKwteJwFm1Gg0pcqB7bV4i2Nt3m5l2Nsp+2lvljmM4MCzbjtmjF4Rvy1dbh/l46xIc2F4ezWDMaWuaNBJvGEO8TpVaXFNZYdpu9i2E6KyzYjNtCHpHZasPSnXVyfViCXnrXZJS5OxfTFkoTWj32oDh1RjhqqJhZ0sjF4oxbwFaNcUvIuJJ3vbOkATaaJkeg1V9zcTjTEVr3rgBfH8QHqenj763VTcXiDNOZYcFm3A4yrFpx+NZCdR5tb08gMtiHu3MxHUJpQhNsKhan/vpESZ0VjUaLTFMs2kxnhgWbcUvIuJotVmwpVOuvRyXoEeDnKwWbjDILNtMelC60YvE+Md5yVjuzTUFRtYmLxZlODws243aQUSXjurWwAfVmBzxFKh4S27o4nGHag9IGNUikjF14gBeSQlQTOGdjJbcWZzo9LNiMW6EZVCoOX5NbL8OCfHTwE941CTa3Dmf2Rsti8X7RalrJrbKgvE4dW5xhOiss2IzboRWH51aY5PrAWL00vmSEWbCZPUFpgxYqiaE0kxTWPLb4zpJGmRFkD5vprLBgM26F5l0vy6yG0eqErycwKEYVbB7djNkXNMGWxeJBPrJ3AbE8qw5W7pPNdGJYsBm3gcSajKnFasM/GTUyLDlEhwB/Lg5n9g9KJ1qx+Ngk1QzuqragoMLAjc+YTgsLNuM2aIJd22hqmpmrd5Qe/v7+0vhS3STD7A0Sa0orWrF4eKAXfNT5QLAmp66pWJxFm+lssIVj3AYyoNSSd8HWKtBYKcE+OqRGekvvWisOZw+b2Ve01uJBAX7oG6kOVbqlSB1bnIvFmc4ICzbjFmjedZ3BgmU71dbhA6KBAH8/Kdjc95rZHzQvmzJ65GWPStLL7oE1Bjs25tdxsTjTKWHBZtwCMp5kRHcU10Mzo2mRqrElo8uCzewvlF60YvFgf29EB6jpZ2FGDffJZjolLNiMW0CGk4zo4h21cj0uWIeYEB8eLIU5YCjNaMXi1A6iv6tPdmmtBWazWWYQGaYzwYLNdHo07zqvvBF5lWYZNiHJQxpZMrZkdBnmQCDR1orF+0R7I8AbsDkU/L6hkvtkM50OFmymU6MVS5J3vTJb9a6p73V0iNolh1qHs3fNHCial01pKTBAiHaEGr5kRy3qDRauy2Y6FSzYTKeHGpsZzVZsKlAn+hgQ7SFb9rbse82izRwolIa0Ptl9or1kGEl0TlkDCzbTqWDBZjo1ZCypaPLfbZVotDjgrQdGJ+qa+l6zWDMHg5Z+qB0Epam4UB8kBavp6c+NlU0jn7FoM50BFmym00JGkoyl1WrFqhy1K1eiMKZkWMkb0lqHM8zB0rLx2agENay41oqsEtXLZpjOAFs7ptNAAu1wOGEXC31X1x3ILWtEdaNN7jMqyRMBAQHSuLJYM4cCzcumDCAJdmyoLzxdhTarsmtlCQ972UxngC0e0ynQBLrBaMH9Mzdgzroi1DSYYTSZMXNZsaxTpKLKuBDVqJJx1QwtwxwsWrE4tYsIDvTDxFTVNG7Ib0BVvTrtJqVP2Z7CwkOXMkcHFmym00DetNliQYPJhh9XFOLR77dg9voyVDXa5fYBMWpxeMvGZgxzKNAyf1RyQyU4/aL08PMErA4FC7ZUymqZ2kaLyEgW49Xftjc1RmPRZo4kLNhMp4A8Fyp6NBqNwgiqYSarEwu3Vcvv1JUrLVJtGMQTfTCHA0pT2shntPQIVTOEm3Y1CKEuwb0zN+KnlYUw22ywiIwlpVmGOZKw1WM6DeS1kCEUfosrpBmzcLK/WG/HylyTXGfPhjkckGhrjc/GJOugF5pdZ3Lgz02VcsIZwmZ3wmRqLiZnmCMFCzbTaSDjJ1vkdmADG8xO/L6hAo/9kIF/tpTBwQaTOQwIPcbqAgt+3iYyke0kLxJqKiJnD5s50rBgM50Kp+bG7AGLzY7IAB0cPHQkc4igdES9E5Zur8DjP27HnM01qBcZxPagNMrDljJHAxZsxo1QEBeo4IrhXoj2V71xNprMwUJpiBaH3Ybi6kbZ6HFPaCmO0x5zpGHBZjodHZnBwWFGTE40yXpGbiXOHEpIfGm8+nHJ3jhnoKcrtH1Yp5mjBQs202noyGPx0TsxKaYWg2N1iIqMQHh4eFNfbG4tzhwqKAPo4SHSWIAOZ/RsQKy/1bWlNdQokr1r5mjA1o7pVKjG0LUivif4W3ByQi3SYgMRFxeH6OhohIaGyr7YJNbsZTOHAkpHlAGkPtiUvmIjQzAxzoj+oQboda3FmbWaOVqwYDOdC2EMSYPJSA4IM2FCvBlxMZFSrKOioprEmvrLsnfNHApUz1rtg02CHRERgdjYWLkMiwWOjamFn765AZqNhxZnjhJs8ZhOhc5DeDp6YFqKAcPjdNJoklhHRkYiODhY9pGl+muGOdSQaGteNlW7xMTEyLSXGhOEkxJrEO6jNkbTC6vJReLM0UAnEh6nPOaoQy2+aTCKysoqlFdVw0NxIDAwUHrUQUFBcnQzraEZF4Mzhwsyh9pCfa0NBgPq6upQVVWFWvGZ3+CDrdW+uGNqjCzx0apmGOZIwILNdAq0wSgaGxvl8KRkBKlhGQ0RqQ1FykLNHCnILFKapP7WlJFsaGhAbW2t/G6BD1ITIqUXzrPGMUcSFmymU0DJkLxs6lpDRlIrniSvmsWaOVqQaFO61LxtEmxKi1T6Qwu3pWCOJCzYbowUOacCk5VawbRsXe2eKAoNNareF+mzTsdCvS/QM/L29JCLtn4o0EyDwWxv03q/e0HPQfO27XabfA4k1GqGkp55106jlJ48PXTw9VbbjvA7efRgwXZTKNpoWZdTg2+W5iEmxM+1hemOlNWZ8eCZ/RAe5HtIDKqWvsw2B+6fuRGJEf6uLd2bluayuwgXZdbyK4y459Q+SIkO5BKFowgLtptC0UY5/pU7K5FZXIfThka6tnAOuLugvboU39tLTfhrcxVum9ZbiLaPDDuYdEDnpqLgBqMZHy3Mw5UTYl1bunf6amkuu9NzKKu34avlpbhsYg+kxwcfdPpiDgwWbDeEoowWmopyRWYFdpbUY/rAUB6usxuivb4U79vLLJi/tQZ3zuiDsMCDE20qAqb2BLX1Rny6qACXjIloakvAaax7QWmM4ry4zo6f11biisk9ZVc3TgtHHhZsN4SijAwqCfbyHeXILmuUHrbWmprpPlBaIE9Ymz0qt9qOr4Un9Pi5A5qKxw/EqGrpq6begC+WFOGycVHcB74botkaSl/0Wd7oxKdLSnDvaX0RG+bPon2EYcF2Q7SXyGw2Sw87p8KIc0bFSYNKjWGY7gOlBa0VMwkspYsqkw5vLyjAM+cPQqjwtA8kE9dSsL9cWoxrJiXILnZcitP90HpvUHqQ1SQWBc/+kYcnzxuIhIgAdhKOICzYbkhLwV6ZWYlcIdjnjUtkwe6mUHrQDKpmVPOqHfh9QyXumNEbEQfgaWuCTUXiXy4twrWTk2S/eEpfLNjdC0pf5GG3TF81JuFpLy7FtVNSkRYXzKJ9hGDBdkN2F2yTEGz2gLorWnpoK9o7yqxYsL0Wt01L3+/i8VaCvawY17UQbDbO3QtKX7Rook12h9JXSb1ap33pxB7oJUR7f9IXc2Dwm8cwbg4ZSRJR6hdMpSxaXXPfWB9M7R+GF2ZtR02jpcnwMsz+oAkxZdYobdFwrJS+4oI9cebwSHy8MAeFVQZOX0cAFmymk6PAamzEts0bsXrtBhRX1brCuwY2Uw0KC4thOsgpoNoTbVpPj/LChWNi8eA3m1i0mQOmI9GOD/HE5cfE4skft6K01sjp6zDDgt0N2LR2LdasWbPHJaOgzLV356ImfwV6JsVjwOChGD1yGMafdJ5rS9dg3gtnISkpAa/8lesKOXDaE23VE9LhhslJeO7XDDSYaKQuNqjM/tORaIf7e+De6Sl47pcM7KpUPW3m8MCC3dWxZmDayJEYNWrUHpernv/GdUDn4t+f30VxdQNOv/4hLF36H56492bXlq6Bp2uaZWfzdMsHRUeiHRukg6+nDpXCC6L6aTaqe8ZhM6C0pAS1jSZXSNfBbrHA7jiwBNdWtLX0FeQNpET4oqzGKOu3OX0dHliwuzrevfHJH7/i559/Fssv+OHj/4OPCA5POwU/z6IwdXn2yunq/p0KOzIW/yW/3XvX7Rg/fiIuP+90uc50TFvRbu6fr8Dm6k9LHC6jaqypQIkQuz0tRUVFsDk6o1F3YNFXD8HTOxBx8fEIC/LHJ0uKXNu6Ag0YnOyLYWf/n2t9/2lPtCl9eeioYZqtSbBZtA89LNhdHj1OOuV0nHnmmWI5A2eccxFoVOiEoQNw5mkUpi6TR/WWe9utNJVgI5ziZTM11KG0tBR1jWZh6l0oTpgMDagsLxOGtwx1DYbmbS4sZiMaG43imxAI8b28rBRl5ZVyXOr2MDTUoqy0BBUVVTBb7TJMcdhhNBpQk18h1/28hBAYjUJwWnoG4hoN9SgrIxEQ11JvENft2uRCcdjk1IgWcZxiN6NCXEtldZ28ZjIohsYGGM1WWoOR7leISVVNPTQHhPZpqK1SvS1x/vYR92kxinOLZ1JaJvfryFiZjQ3yXssqKmFre7GHkLaiTV6QCBX35Ti8HrZixQPpvREvxG5PS2JiItYU1LsO6jxYKrZi0iXPim++uOauB3HuaVNgOkBvtLMiXmHYbQd3T5poU/qiDCF9UvqitKVlCJlDDws204ovHzweMbFxWL/qF0RExyI5ORn9Bg+BiV5waw2uOedkRERFIyEpGSkpyYiNjsIp533sOlrlkctGI230ZCjV69G/RySSxDmSkxKQkNILxQ0W116EHbNfuwZR0XHid1KEEU9AREIK1lY1Iv/vFxEZGYfX1ql7juuXLNYjcckL/6gBgo/umCauJUYeK68lJgonX3EnSH418he+iujoaNzx4xqERUQhUVxLQnws/so1wW6qwZC+KZhw+5tY8sXDiKT7TUlBQlwMLrnrXXG0BV88dhaiYxNkOJ3//q/WSrFvSeHSmUgKj5TnTklOkvtNe/irVtdBor7ux6cQHhktrzdZ3Gto8DRUeJpd2w89mmiTWJM3JDvcCKE+vJ6PF85+9h7cftdduIuW/7veFQ5MOfkqNYyWm29GPJWjdjJKMterX459Gu++9DS++3U+bpqYqIYxrdBEW0tj4qtMW9rCHAbEg2XcDJGDVex2u9LY2KgsWJenfDQ3Q6mvr1dsNpvctidsdSuUMBHtg86+1xXSmk/vmkpvmuIX7yE+E5Szz5qmRCX0U4RgK38/earcNuqUK5RPPp+pfPC/J5UksQ74KE/OzXGdQVHuPHu4CNPL3wFGKk8994wyaWC0PDY87Rql3qbut27+ezIMg6Yrn337k/LpO88r/eGl/Lq1RKnaPk+55cZrlXh5DihnXXmDctNN1ytfzs1UnA6Lcue0ceqxcb2Vp197W/ngjWeVmIggGTbyrBvUHxDk//22DPPw9pOfU04+W0mNj1aWlVgVq6FGSYgMFOE+io/YFjv6AuXFJ29Xgum88FMGD+ktPj2Us665W7nrMvW5ePnGKTsNrhsQrPn9XRlOy7Nvfqr88M1HyoQEdf2CF3527aUoJWu/VXy89DL8nFseVh65/XLFQ6fuJzROeeLXna49Dy2UHqxWq1JbW6s8/PU6ZUt2sWI0GhWHw7HHtELbab/i0krlhZ83KTU1NYrFYpHh+4WjQbnQ9Xz+3FTuCuy8bP71eXmtp7y13hXS1ahX+kZC6Tv9Rtf6waGlr7q6OuXVWZuURRvzpF0i+7Q3W8TsPyzYbgi9CIdbsD09Byl/ZZTIMIdNNdLFWxcpf63aJr9rLHrrAbl/8mWfK5opVwUbSs+Jlyr5tQYZVl+0ziXuUFbm18mw+Z/dI9dnLsqS64Td0qiY7dqZbMqjx6rHZBQ3usIUpS5/uRLsLTIU8SOVtXnVrlBFadi1XhmQFCz2D1PmFqi/qwl2eHiAcuuXyxSR71AcrvM3CzaU8+55XbHIUEWZdd8lMozOc88zCxWbg56pXXnmqsky/Kn5+XI/h7lcOa13iOLh5aPMWV8gw4j6ko0ucU5XMmut4jYalFsGq/dx27uzXHs5lKzlPyjxEf4yvOsKdn2zYG/cXbDrclcol1x0kfLiwl3Kmy8+opw8+ThlyrTTldWlIjbEc3vv9ReVKy8+Vzlh8kTlmGOOUy664jrlt4Wtn1XFpl+Viy+6WJm5ukCZ+/FDyrmnnij2naicdeGVyi+r8pWWd2msK1Luvf1G5eQTJikTJ05SzrvoKuWl2Rtk2n358TuU08cMk9caPXy6ctXV1yjXPfyeImJQYqnJUZ5/4BZlxrQTxPknKFNOOk259a77lZ2lta49VF58+Cbl1qffVbLWz1XOOeUkZcLEycqrX/0ht239/VnloosuUTYXFCjvPHaLuK9JyjGTpig33PacUlwvhK9ip3L3rdcoUyYeq0yZeory+BvN75WG3VyvfP3Qfcq5p01Xjj3mGJEJPU25+7Hnlbqm90bFbjUpzz9xvzLj5OOVY46dqJx/xa3Khvx8pW8MC7a7woLthtCLcLgF+62/OvYwnE5hzA0G8ZLWKtv/ekXun3zBzNaCHZislLrWVazKc1NVw700UxXZxV8/Itd7TblCWb4xS7Ha2167RXm4SbAbXGGKsurzW2TYtS997Qpp5onrz5Tbzvt4k1zXBDt90jmKo82zaRLstAuE39GMIXuWPGbgxGmuEJXFHz4uw49/eZlcb8z9T64Hhh6r5BaWKCUl2pKnXOrnI7f9nVWrWIWhp+9AuLKtQssWqMy6d5Lc1l0Fu2zdb65n00Px9oASEZWohAdHKnN3WZSfr1FLZRLS+ivHCnEdN3KQ4uXad3mxmiEj8v76n9zPH2nys2f6EGVQ7yT53TswQsmpNMr9nLZG5caT42R4/5HjleOPn6T0TYpVYhIvVszitq48/RglKSZSbkd4itK3Xz9lwORbFTraUJGlRIWqmbuotAHKhAnHKL1TXKVGA6coO2vM8jeIk0emiPBgJd6frjVMSYoLVy67/225beELZ6vnQIACr0BlyIiRSjT9nlimnXudclIfKHp9qDJy1AglyM9Tht/0+lIRV/JweQ8PXXaCDE/qNVCZPGWKMrR3olzHoGuUKpNa+uOwGpXHLxopwwMi4pRRo0YqUfJ6xBLLgu2ucB02szs6DwzskeBaaUZx2rF50Y8Yn6aHf0AAQkJC0ffku1xb2+DhKRu3tYSapbRkzKm3ICQoANkLP8O4Ib2Q2n8YlmcUywZve6K+pFh+9otLl58tOXmUWt+4OCNfWieNwL4XyPq2dvHx3+3aVFpfR2RCkPzU7quhvFR+NtYuRs/EOMTFaUsPfGlS6+pLa0ww1lTK78AwRIe0rrf18eGhHIn+/fPgdeJDyC3dhYrqMpyY6IWIoWfh3dmrUJi1FYv++xfLVm3EI2MHi73z8PIni9QDW2DU5eLYp2YhM3MDNu3Ixv3n9IK1sQov/blJbrdVZeHdv0pEOjgLK1csxYIF/yIjNw//LXgRIrOAT35dgrnv3yv3Pf2Z35CxbRu2LHwDfooDX9w5HRW1jZhy3bMoydqCxYuXYEdeGSYMTUX1lgW4+erP5XEa4eH1KPVNR465EgXFVfj0qRtcW1SqPO14a85KbFizGmU1axDrocOcHz7Aguz+WFNegdWr1uCfT+6T7Q5+f/empndi2+/v4Jkv/kZYXAq2btmAhX//jfUZ23DXMT7A5o/w67875X4lW2bj8a/XAJ6+WLR+O1atWo3svG0ID/YViVLuwrghLNjMPvPljZdixKRzsaI6Cs+89glm/fYbPn7iwLtZeQVGo6qyDKv+/Q1jh6ajMHMjJgxMxouzN7v22DN22FzfmjEb1Jbok1Pj5eeRICB4OP5bskwY8cWtl2UrcObgKLGHJsp+zV+ZVuzI9ML2bx5FkLBIHnoySzpMvPld3DB9lLoDITJcF99/qvzqods9izXk7Bfx78OnQZ3+xguXXX+P/LYzTxsdT00bCv5DVrkrTO+DPr3jm6LFKVKVxNVbgbDW5OLOLzPl95ce+z+0nGD0r29flJ+b836QnxrV1cCnsxahB+UEBB6erU3tE5/9jZum9FdXQkeg5+Ce8utH/y7A0HD1DoafcTWGiM86g6VJsL+YTY0uQ/HF8gwE+biuxCMI17/8sTTmq3J3yKBVK5bIz0te+wPDkoLl96CoftiVuxYp6irjhrRORQyzB75cu0xIZAoWbNyBB2+/EqedeipOOels19YDQ+8dgJETT8XyNZsx99Nn4HQ68MArf7Yjxc0EhofKz8052fKzJfPWqWEx8SGHXRsDokiMqUDCgaEjx2DChAmtl3Fj4O+th19omNxP+P0ormrdKjxrx+FrJe5OeJz4NuJCd281nr9tGR6540qcf+65svvhVY+8rW5op+eQX1KvVgbN10cVdS3MO7IfXrzsJKHYVRgW3wvTz7oAvy/ee+aQSkjU4VPOQs/oAPlNIyD9OBwrkgGJaqs0mzwZZ0+IlS2n2yMuPqZV+tTJfvJARGyg/CR0vrEYMEh8tijoqSraJf7W4q4LZ+CEKVMwxbVc/X8vyUeyclu53K80a5v4643TxvVt9Tv+4Unw63yN85l9hAWb2WcUGugi0AehPuob77TW46tvP5Tf9x8H1s76BBm7qtW+08LT6Z2Wom7aS7Lse8KlCBS2+MtHX8Bv68mAqexY/Cm+/nwufMP6457paa7Qw0dQ/ACclhaIxoYMPDtrCaxN/aoVNNaUYMnaTGlEvYPjcJMsva/Dq5/Mgk3s5rRbseDtJ/DwnK20gWmbQ1Mc+O/1+zFwwDF4+pM/UFlvkl3TvDz3kA1rdorbR++Huz76GT+++RiOH5+EOb98h9MmDsa5d7wE6x76Wut0rvTYP0EWnbeChNYoMgttL2tvQ8N3/HN7RJGethdSkuIQ21QFE4fk3gNx8cUX45YZw+V+dqOaEfTU7+F5MW4HC3Z3Q9OUAyCtb2+gMROTBqbjxddeQ2JSD9z1v8WurbvT9qdarzvw4/+uRv/kCEw98yo8cPc16DnxEpEi9Xj4/05oqlNu73KDk8fh3JGDReLdgtOHJ2PyjAtx3pQx6DvxKuR6+uP8i55HXPuV0vtGB89ot2CfaDz+2ovwc1jxwvmTMHTEsbj3wftw0YnHITg8Hsde85baF1vvj8e+/1KIjQc+e/ACpPcaj3HDfHDCLY/Dy4fnL28Pu7EW5z7+JhoRiN8WbcKCuX/ghx9+wIdP3OLa48Dw8PLH2eK5L1i6Hhn/fIYIkfP78d3nsLOaBvrpCJe6blsk54FuiaMmGzsNQkL9fDpoB3Fo8fTzFX9D8MR7n2HmzJm7LVefNFLuF5pAbVAcyC1rMziN3Q7Hwc0zwxxFWLC7G15h8BHvvI9vy5q4ZvReNHApfdk9Z/7O57Pw7IVT0VhVgvvuvBMl5SlYsHopJtLG5pI86PXCdO12vAe8tNJEWUfphdvf+w8TBgALZ32K51/5WChxLN74cTkeO32Yup9A2FeVFmWLOuGNf7x4DX776GnEivV/Z3+LHxauAnqOxZ/L1uOTN9V6TkLv6Sr/C9i9HFBH/+i8vq1F09s/HJHi089LrVfU0KpNA4OaTfPQGddjV95KTI8IRsaGpXjpuRfxzfxF6HvSWfj36wfkMLBE1JCLsXn+5+gRCuTnLMeqLf546IP5WPnVQ3K7n1f78dFdcQhVcdKIWUlnYvKQOFeogo3r5ri+HwBOu/CkXd8FfY+7HHdMEef20Ink2rEnGhzfE6Plt434+Y8t8pvGZ+fcKttwDUg+WQ04zAxL7CX+VuLcmz7eY4FC73Sq+3fg/ns/QtP4fA4T7k1MR1aNa51xP9TG4ow7Qd0lDrRblzhacTg63o/CbdQlw7W+O07FbDQo9Q0Nis3VxcfpsCuyq7ILpwjXtrVEu+7WOBST0ag0NDQqVlvbbR0d04zdZhHHNojFIO6r/auWXUxc39tC12pv51k4xDG7n46upaNn51RMBvW5mMyWDp+v3SquV8SV0WRtuqY93d/BQtfhDt26vKZ+oLR8CnZzrRLtGgjn5EtvVebN/1M58fjxio+neq5zn/rbtWdzt66xt/7qClHJWfSJDD/xyb/k+sZfnlb8AhKUE066Ufnpj9+UO2+6WIn0heIfFqOUNajd7bb8+qw85vTX18p1Faey4ed7FJGlUhAYq5x76XXKhx+/La7nGEXk9cT+Q5RVLcYJkN26EiYrzSHNaN26Pvo70xWiMn54Lxn+e1Zz90VFMSoXD4ISkthXsbr6WBuKVig96Do89MqoiccrH37xjfLtlx8pV0w9XunTI16Zt6VY7mcs2yzPR8vgsWcrzz57lzJ2cB81TK/nbl1uCnvY3Q4aStBT9SzbgcI9aZhB1/ru6ODj54+gwEB4uhrK6Dz05KQ0QQ1otG0toXOrY1q3xAO+fn4IDAyAl+fuXmb7xzRDHnSguJbAQH9xX+1ftRw20fW9LXSt7XlXHuKY3U9H19LRs9PB1199Lr4+3h0+X72XuN6gIPj5ejVd057uz+0RJiZAbZsnnmk7z1lLJ1qLZxd6nxCsmf0pRidE4a8v38SJU6dj/j8luPG2GyBP16L8meJK4tU6zSnauWWJDpA4YCymjIjG33PfxdkzTsOr73wFfa8JePynRYgKVEtgSJUlrmNUdBh82jP4+Ml70M/PjB++/ADXXn0z5i1cioGTzsIfq2dhVFxzYzRZ5y3uldSxLR4i/RBN1+YiXEc/HIiANs/BKXanpKQ9Of/4MVi4cg5OnzQE6xctxLWXXYgLLr0GMxctQ8KQyUgMU4u6/KIHIm/FzxjdMwCbVvyEBx98BVvyvfDaT8swLC1KvJ/tp0+mc6Mj1XZ9Z9wEijKRe4XZbMbKzErkVphw3rgE+AnhU8f05ZeRUaG0IrwdOXHKy3/m4IIxsUiNC5UTglA66SitUPoSHjVq6434clkxrpucBH+RIaGGX00iu48Ifxk2mwJv7/ZreW1WKzy8vVt1l2rGiYrSUhjtQFxiPEhW7RazEGdfITrqHoTw8qBv5xwUThNTNN+nOslLdW0DPP0CERupteBvho6hCS3axWlHeXm5nDAmKCIaEUFtRxugXdQOhz7iWbWF4sNss8GHZlBzhUkcNlgdHuJ3W9+Bw2EVcaEX99D2zhQY6mtRSfchMoERkVHw7aBapaxwFyyKF+KSYmU+xyF+3yni0OsQZBS19GUymfDxv/kY2SMYw9Mi5VzZlE7YFh1a9u/NYxiG2U90Os8OxZrw6lCsCQ9ExcYjxSXWhKdPa7EmSGDbOweFtxYNHfyDQpGYlNSuWBMdijXh4YlocT09evRoV6wJD5p2sh2xJuha/NqKNaGnWa92vwO9nmbCau/OdAgIDkMKTWYTF9uhWBMxiUlIdok1oRcZmEMh1syRhwWbYRiGYdwAFmyGYRiGcQNYsBmGYRjGDWDBZhiGYRg3gAWbYRiGYdwAFmyGYRiGcQO4H7YbQlG2z/2wnbV44Mb7ULWXaE489lw8eulU19rBYMWVx/bCZ2tt2FRVgkF+ruB9woFPrh6Bqz/ZiJdmrcPdpzUPUXq4Wb/gJ7z9zVxoXYxpohPfoGDEJQzCORecit5JEeoGN0PrJ3s0+2EzXRfuh31k4Tevq2OvwoL5czFv3jy5zP3ja3z44Ydi+Rrz5qthtGzOLHAdcLAIQ19XI3TbDtt+TzKgoLG0WH5zGOW0GUeMBfO/xccff4ivf5uLhQsXYsGCefj0/Vfx0L1Xok9yJB57Zw4sBzDDUu6yX3HOOefhvf8KXSEMwzAHBnvYbsh+edhtsBs2ITpwCBLPfwCbvn3WFXqIEddmtdPIVgcwOIO4N4vFAZ82E3Icbl5+8ALc89x3eGtNLW4eESLD7OZGfPrUdbj+2W/kMJOXv/InPrtzmty2r6z76l6MuOQlXPzeBsy8fogr9MhxxD1s8XuFG1cgo8Igzu0Kawe6pvHHTUVwB5PQHFbENe7avl5O7ardirgcxKekIi01EX5eXiKcPcN9gT3sIwt72N0NhzoVP+ztu7/VRTuwbNlqmG1ObF/5D9575z38szareVxkpw2Zm5bhm88+xFtvvY8FyzfsNpVxcd52rN+40bUmfspYhZXLliOviqYwdGDxnO/Fse/i94Vr1B1a0FiZj3XrVqHOoM7n67SbsXrZMmwrqKA1bF0+Xxz7Fr765W80mNr+MmFHxrpF+OzDD/HVD79i/eYt2Lw5A5u3bINZGJe9YRG/p+HpG4hrnpqJfz97UK5//8TToKtowmlFxvol+OqzD8Q1fYB/V21uNYNSdmYGdq6ulN8XZWzDli3iOrZlt9qnonAHZn33pTj+HXw/ex7qLe3dkxuhWPHICdNx4olTMXVqx8u0adOQWdboOuhQ4MSyWZ/jlVffRp1pT/NYiUsUy0UXnIOTTmp5PVMxpH8aIsNiMXryKajY8yn2gANff/wOPv9pvmudYQ4h5GEz7oXwfuRsOAcyW5etboUSJqJ90Nn3ukJa8/Htxwp7plNuPOsUsmtyiUwYrRhtTiV7/v+U3smxTeHaEp9ymlIk1FDjjjMHKgjuqdS61gsXfyz36zvlfmVCql+rY3uMPU0pqWs+eO7TJ8nwT//ZKdcbS7YrIpOuRA69QrnkmN6tjo1KH6Eszq6W+xGOuizljBGprfZpuby0qsK15+689MD5cp9XVpS6QlpiVk4aliC3v/BPkQzJ/OMZpWdCdKvz09Kj93lKiet2RqaH7radlhVlZsVYlaPMmDC0ne1pynd/b1NPcAig9HBkZ+tyKiUZ65Vly5cry2lZ8rcy0nVvz384Ww2T4UuUepPNdcyhwKLcNxaKzkOvbC9pb56sZui+Rw7qKa/plV+XKevWrVNWLPlPef/1Z5RR/ZNc8TBYWV9Y4zpif2hQRsVBSZlwvmu9a6OlL56t68jAHjbTCg89TZCv4IMVszFo0lWY+eVHOOf0sXJ6612bNsAjpjde/PgXFJVWoCBzLc5OT0Fx/m+47vX/pFUmdB40FrOuqfhGXQe2L3gemzwH4cOv/sXyeV9jWM9A5K34DZ/Pb/bGPfTq+Mw0V7X8lLMYAZUbPsNPWTbc99j3yNi4BDPGJqJi51q88NT7cjvx9m3n49e1OTj16vtQWW9E7rr5SI4LF1t88Mk/q3HDyANtOOaDGX3U4uyvZq+S95m3bg38k/rjtS9+R3FZBfK3r8KMlATkZX6P299fKvd57f2f8OpN58jj+lz8Ov6aOxez/1qEIZE+MDdWYlWJFTc9/Co2Z+ejrDgPr55xAryQjXtf/XCPcx13bnSI7TsU48aOxVhaxo1GumvL4NGj1DBajjkGQS2qPWiCkF25O7Fx/Xps2Z7VbumJsFcoL87Hpo3rsS1jJ+oaLTLcaTWhqqoahmpKuQqqaqtRWVmF+kZXadIe6DtoEIYNG4Yxx0zEdf/3IBYtXoTjRtCc05tww12f71Z6ZGqskSUn69dvwPbsXJhbNNSwmepRU1ULmxkw2q2oqqHrqISlxT5OhwWFuVniHjZg89btqKozNL03DLNXVN1m3AnKuR4uD/vTu6aS/VDCY29Q6vdh6uNd/30o90++eqai7X7n2cOFh52q1LvWi5Z+Kffxj+6tFNc3e9Pb5r4rw0fe8ZkrRFHmP3emDPvsnyy5bijdKT1seAUrv6wqkGGSmtVKvB5K0qQLXQGKMnYoedeDlJ0mV4Bg1iNnyfO9u6w9z7mZPXvYivL3U+fJ7UMenN00j3Vb8uap8zIP+r8fmvZZO/MeGXbxextcIR0jDL7SIzpQwZBLlRa3cFBoHlBnnQ+bqCnKUE517aMtPkHhyvztxU1pym5tVN6+69RW+8AvTFld2ahk//FI63DXMn7GOa6jW0P3rXnYs7Nbzj+tUr7jn6ZzrClRY8JhMymfPHlLU3jzMkXZmK+WJf315Ph2tkN54nuau9upbFk4s53tYcqnC7LbmXvdPdDSF3vYRwb2sJnd0Xngu38eRVAHqcPpIG8oF5s3b8KmLYvVQIP6sSfCT3kYMUE+rjUgIpk8GWCfen6Nug7TRiW5VgShfZEY22paZBdmmFs0MN+6vUF+BnYws9K+0kDzOwqUqtZem8NuQ0FuDjZtomfxnxpIVfX7QVVZCbZu3YRtmRthtogHqTqO3QJnYz4m9RmG38X3C257Flsyd+LLZ66FpaEaUwelY32BGn/L/ngLN78i9hp3GVZs2o6l877DCJMB5TUmhKefiKeeehSD5J463HDvE3j66adx3RU3ypD9JTJtBE52fV+wMVd+GmuycfczbyFhyBR88+cCrFn5L86RDaoW4Ip7n5H79Jp4I1544X5E0kp4Xzz9wgvyOqYPHyACzHjrtkug9/bD0x9+gzXr1uC1q84T4TW4cko/7Dik9flMV4UFm2kXL93urbTtNTtx2eTxiArxQnJqKgYPHoJTbv7CtXUfMB5EcjNrheQd8+DUKPF3J06beBpmLVyCdx68EK/8tQhIGIpJqfvVIXw3dmSpwtF7cLz8tFVl4KJJYxEV7I2U1DQMGTIEp935i9y2Lyg2I54851SkxgYgMjYeAwcOEec4FqV15Hh1H3778E1sajRj6JUv4/OX78OA9F645IF3MPvVi8RDNuDrP/6R+xlqqLmfDt+/+gTGDOqD8VPPwypbPU5MjUBo7wl4+OGHMWMC5TU9cMedd+Ohhx7C5WcfL4/dX3QevjhuoPrdblXjwy80Fb8u24zs1XNxwbTjMWL0JPxgqUbv6ECs35gl82hpky7Bvfc+itQEoOegYXjo3nvldYxMEzlL+ODOb9agrKoWD11zAUYMG4HbP/wCz51OYm5FXmU9/QzD7BEWbGafueu8i/Hlv8sx4Mw7sGZTFkrLyrDxl0ddW48+CzbUys+qov9wxpRjcfNz3yIkcTQ+ff0zJPkfRDcxZxV+XrZKfAnBFacMlRmH66edjW8WrcSwC+/D2s1ZKBPPYt13d8rd94WNs9/A4z/9AWfSeHw5bwWKSkpQVpyDpMg9zMXcBVm1hdov+OLqK09BblYmtm/fju07shAx8EQRCmwpUPvlhwSEir8K7rjlRnz3xwqY7U54ePrAs6n7VYuMzj70Btgj4pQ6zTK66p/1Xn44dvhA+HjpYTI0ory8FOX1Znh6i9+yebTITLrqq3e7Bg+kDxiBiEBvkQmwoKqyAmWVNQiMVmvJdY69ZUcZhgWb2Q+2lBcJ13s0vvvyVYwYlIaY6GgEh5BX2xlw4p/MEvQ/8/9QmF+KksJClJRXIXPbIlxx9v70f25tOJ12A966/SKsKqpDz+NOxykpqqe+iTw+r2PxzcfPY/jANETTswju+FlU2+wtJQWZK/+W68+8+A4umToG8bGxCA8LgYfHke1/frQxVlO3NzNundgPffv1Qz/XMvbEK0QomhqWjZpxI8aPHITyDfNwwanj0DN9AGb+9g/sjgMYzWZvOCxYtEn96ufK6CmKAxmLZ+P841LhHxiEmJg4xETGYVvhPtQFuagp3IGn77gIgQG+iIyKRqw4x60fZrq2MszeYcFm9hmdXi+8iVX49b8CdWCNmh04/+pbXVuPNh7w9vHFtl/eQHCAP+ISe+C4Y4/DjLPOwjvfzodDXO+++F01VdWoq61FVUUplv71PQZ6BeLWN+dBJ1yul9542bUXeWD0LBbjz+WF8lmYq7bhrGsfcG1txuHKACx5+H00WuyoFJ60VXhf5LERv/+3VF6b3VyLh86MQH75flaAdwkC8FNWOSoqKoTnWt5q+e/Vm+UengERWLp6E8ryNuKE8YNRlr8dl55+PO7/aeM+xev+0FheiNmu7+MGpcjP6u1zMXLiDHy/KB8nP/Am1m/ejKy8LKTHyM17RTEX4vSkvnjkf9/APuUaLFi6Gjt2CgE/kz1rZt9hwe5mKHbyRfdOe/vcd8NF8vPWE9LRKz0dwTEDsUptk9MubbsmtTWse7qO9ra1DWu7fsN4tVFaaGgohvfqgezsDPz1yy+4+cITkTLqJCGsHZt2vcuzffqUfggNC0NkdBwmTDsfGSIsZdKFWLNjF84e1OxBP3bT2fLz2uPoWfRCUMwgbGpn9NGh0y4DNa1rqPsQSXGRiIsfiu01dhx31ZPw9vTAd09ciYTknohLSMGLf6nHdCeC4xPEXwuKqz0RGRmJqKioVouPd+sSh7DEgZi/eC3W/P6hXH/lI+Fly28tOKjRtRz45hW1aiPxjMcxIk5trLjut/dkPfXjHyzAnGdvwdCBA5GWkoaAINnEbHfajJRWuuE/UPPM8Kjr0Tj7fRw/fiR69+qNPoO05m0Ms3dYsLsZ+uA+eOH1l/DANae5Qloz5sxb8OLLLwvPIdAV0szU657Funm/4omH78d5F1yAp57/DKXVFfjxlZfw8FUjmwqTz7jyHrz03EPCb1IJTR2DV8Q5H792dKsC55DYvnhZhN961mhXCND3xOvk74/prYqjd1AUXn35Fbxy/xltWoT74s4nXsVDt1yqrjZm4JHv1yJ93HnYtqsCa3fuhM1mQ0NFHi4Y1wtF69Zho6HjLMIFl96K119/vcXyIX78fR4ysguRvXAmhqerjc00Ztz2JlbP/hGPPXgvzr/wIjz70leoqK3Ed+JZ3H3xUNdegFf4ACzasQLPPf0k/u+W2/Hc+x8iPdQLET2GojhzDV5/9ilcdfkluPXOJ7E+uwzLP/sILz94IbpLwfj0Y8aJv3bcdu7p2FhSpwYKHHYT/vv9W+SWUWM/O2a/ejeWZRRD5rlE5irAyyXTtuZMGNUeK04nNuZUiNycDY2Ney+tsFpscohfY2Mdtq35DzedNQXXvTJHbvv8mevh5bKQOkWNkVqT2k5CcVgx96PrkFOojmTXErqi3E3ZyGsU1+gww2Kja1XHE3CEFsLhUK85b/3PeOFz9bcYZp9wde9i3Ajq33ig/bC7KvXr3yIrqFzxwCeuEBWHqVq5clJvBZ7RyrZ6uyu0+0Dp4aj2w7bXK+eoGtZ+P2xLpXLt2EFyOy3TzjhPufDc0xWRPZLrMxfn0E7KA5PV9VGTTlUuu8jVH9vTR3nzn0z1PIJZr17ZdJ7hSfHKxNOucG1pDd33qMFqP+z2loR+o5RZ61v3xy/d9ofi46WX208670pl+vEjm49JO1sxuvYjLpk0QIYHBgcq/XVQXvx5keJozFcG9QiX4enjpytXX6aOD6AtczYUu452L7T0xf2wjwzsYTNdgqB+kxDtpcdnz12FAZfdhv9v735Co7jiOIB/nd0d3K7rFmNaSsxs/QMmVqWCIvWkCBVrKVShHvRgwYsV2ov0JgVPehC91INCK/ZU60EwooKhWlQw2rRqrRIFSakIQbSGbWhDdvV93+zTzbpJNsGNmc33I48YMzOZzfzmfWfHvDfH29pw7IeDWPTeYnx/vgstSxdh/jSV+7jzfKz4MIsgyCKdqnDfwG/AwYtXcOLQN2htbsa1jgv45dJVJFsWYP+P7djwwWwuhK+P3MDGNVk8uNuJs+c60bxwOY7+fBPbV7p51IB12/bhK7NMU1MTep7GMG/5xuJXBuNdni9XtSCbzZa01di2YxfOXb2Nv//swCfvD/7P6bdbP8LN9sNYYvbxxoUzuN7VhwNt13Hg07UIZs8cdOfo0E9H8fGyAJl0Br2zArTOnQsvFeDi5cvYYL5XX/c1nG7vwPote9HdeRLvBgGSydfwEBSJHD2tK4J4yMzV65ie1lXP7l45hc82bcVvd8KhQM4Xu77D7h2bkU6+PM1KvWOtmHc7r/V52K6LGb4uw5rO5wt2Oc/UsVe2vK37fN7eFmedV3qiFpfJm2XMRhDnL0m+YoVC3u6j55nvH/PYgdq3yOWvzbz3LL4Wz+zri5/X8/0zER+Lm3OV65vGcWTD/ngmKO4760tP6xofesshdWPesrX49VY3ep88tuOie3oeou//fny78/NJGdYTBTvtkTtuE9ImBBOJRHhRUGF5biNmvpZI8KKh8va4DNevRViT20eGsN2DIV4bg5r7URrW9Hz/GNbhP9jJXipsQuQlCmypK1NicaSnv2nHRTc2NiDpK6hFpD4osEVERCJAgS0iIhIBCmwREZEIUGCLiIhEgAK7LoTDZuzwkOJHNbXSFhZG+GHU3PpFlbavNjmbjC+Nw44gHrLScdhn/nhopxK1Q02maAIGKWVq5WkBAwN5/P5XL7avDjDnncwoxmH/iz0n72FBU9oORfJUX1KmYP7kBwZw634O65e+hSVzGjQOu0YU2BFUGthPenN4lPsPiXgCvp+wJ4mIw5Obk4309/fbCTsaM28gnZ5WdWDncjn0/NNnJzLx7fjjuFmnuJCIwbpiffGicMb0qciY+lJg14YCO4JcYPMkYYfKjpXC2Z8U2PICa4UtnF0LdrYyNt/3RwxsPjyF9cULQ37OCT+GW0cmn/L6YlCnUilbXwrsV0+BHVHsQDklIDtTBjY/J50gUs6d4rygY4fKd9cufIfCdVhfrC3WmOuQVV9SztUXA5q1xRrTxV1tKLAjioeNIc2OlM0FtshQ2KGG02WOfCeG9cXG0FZ9STUYzuG0qwrrWlFgR5Q7bK5jdX8XqcR1nq4jraYzdbWl+pKRjKW+ZPQU2HVAh1CqNZaOVPUl1VJQ15YCW0REJAL0K8UiIiIRoMAWERGJAAW2iIjIhAc8A1gSb+QH0ylhAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit()` : used for generating learning model parameters from training data\n",
    "\n",
    "`transform()` : parameters generated from fit() method,applied upon model to generate transformed data set.\n",
    "\n",
    "`fit_transform()` : combination of fit() and transform() api on same data set\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Imagine we are fitting a tokenizer, if we fit X we are including testing data into the tokenizer, but I have seen this error many times!\n",
    "\n",
    "The correct is to fit ONLY with X_train, because you don't know \"your future data\" so you cannot use X_test data for fitting anything!\n",
    "\n",
    "Then you can transform your test data, but separately, that's why there are different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10608, 17)\n",
      "(2652, 17)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset, stratify for class imbalance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (10608, 17)\n",
      "Test set size: (2652, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\IDE\\Anaconda\\envs\\vision\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\CODE\\IDE\\Anaconda\\envs\\vision\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Encode target if not numeric\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder() # set id start from 0 to n label \n",
    "y_train = encoder.fit_transform(y_train) \n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7858220211161387\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate acuracy on test set\n",
    "y_pred_lr = log_reg_model.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Basic Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\IDE\\Anaconda\\envs\\vision\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model_sgd = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),    \n",
    "])\n",
    "optimizer_sgd_no_momentum = SGD(learning_rate=0.01, momentum=0.0)\n",
    "model_sgd.compile(optimizer=optimizer_sgd_no_momentum,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# stop if no improvement make after 5 epochs, always save the current best weights            \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4248 - loss: 0.6840 - val_accuracy: 0.4270 - val_loss: 0.6722\n",
      "Epoch 2/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4214 - loss: 0.6730 - val_accuracy: 0.4270 - val_loss: 0.6659\n",
      "Epoch 3/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4190 - loss: 0.6670 - val_accuracy: 0.4270 - val_loss: 0.6612\n",
      "Epoch 4/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4077 - loss: 0.6656 - val_accuracy: 0.4274 - val_loss: 0.6535\n",
      "Epoch 5/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4314 - loss: 0.6515 - val_accuracy: 0.4647 - val_loss: 0.6441\n",
      "Epoch 6/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4554 - loss: 0.6436 - val_accuracy: 0.4585 - val_loss: 0.6317\n",
      "Epoch 7/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4743 - loss: 0.6337 - val_accuracy: 0.4892 - val_loss: 0.6196\n",
      "Epoch 8/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.6215 - val_accuracy: 0.5467 - val_loss: 0.6061\n",
      "Epoch 9/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5628 - loss: 0.6038 - val_accuracy: 0.6084 - val_loss: 0.5921\n",
      "Epoch 10/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.5905 - val_accuracy: 0.6258 - val_loss: 0.5766\n",
      "Epoch 11/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.5766 - val_accuracy: 0.6404 - val_loss: 0.5605\n",
      "Epoch 12/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6242 - loss: 0.5587 - val_accuracy: 0.6343 - val_loss: 0.5439\n",
      "Epoch 13/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6354 - loss: 0.5448 - val_accuracy: 0.6206 - val_loss: 0.5292\n",
      "Epoch 14/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 0.5276 - val_accuracy: 0.6517 - val_loss: 0.5167\n",
      "Epoch 15/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 0.5170 - val_accuracy: 0.6678 - val_loss: 0.5077\n",
      "Epoch 16/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6396 - loss: 0.5013 - val_accuracy: 0.6456 - val_loss: 0.4936\n",
      "Epoch 17/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6534 - loss: 0.4941 - val_accuracy: 0.6682 - val_loss: 0.4863\n",
      "Epoch 18/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6510 - loss: 0.4833 - val_accuracy: 0.6631 - val_loss: 0.4752\n",
      "Epoch 19/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6504 - loss: 0.4777 - val_accuracy: 0.6654 - val_loss: 0.4676\n",
      "Epoch 20/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6507 - loss: 0.4793 - val_accuracy: 0.6371 - val_loss: 0.4593\n",
      "Epoch 21/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6627 - loss: 0.4587 - val_accuracy: 0.6701 - val_loss: 0.4534\n",
      "Epoch 22/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.4462 - val_accuracy: 0.6649 - val_loss: 0.4446\n",
      "Epoch 23/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.4521 - val_accuracy: 0.6659 - val_loss: 0.4418\n",
      "Epoch 24/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.4453 - val_accuracy: 0.6376 - val_loss: 0.4347\n",
      "Epoch 25/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6501 - loss: 0.4449 - val_accuracy: 0.6579 - val_loss: 0.4249\n",
      "Epoch 26/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6629 - loss: 0.4268 - val_accuracy: 0.6612 - val_loss: 0.4334\n",
      "Epoch 27/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.4208 - val_accuracy: 0.6607 - val_loss: 0.4129\n",
      "Epoch 28/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6657 - loss: 0.4129 - val_accuracy: 0.6861 - val_loss: 0.4305\n",
      "Epoch 29/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.4219 - val_accuracy: 0.6682 - val_loss: 0.4209\n",
      "Epoch 30/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6669 - loss: 0.4062 - val_accuracy: 0.6664 - val_loss: 0.4063\n",
      "Epoch 31/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.4074 - val_accuracy: 0.6555 - val_loss: 0.3921\n",
      "Epoch 32/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 0.4042 - val_accuracy: 0.6536 - val_loss: 0.3891\n",
      "Epoch 33/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.3742 - val_accuracy: 0.6673 - val_loss: 0.3836\n",
      "Epoch 34/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.3858 - val_accuracy: 0.6664 - val_loss: 0.3781\n",
      "Epoch 35/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6665 - loss: 0.3927 - val_accuracy: 0.6682 - val_loss: 0.3832\n",
      "Epoch 36/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.4013 - val_accuracy: 0.6602 - val_loss: 0.3686\n",
      "Epoch 37/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6782 - loss: 0.3743 - val_accuracy: 0.6706 - val_loss: 0.3711\n",
      "Epoch 38/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.3819 - val_accuracy: 0.6560 - val_loss: 0.3611\n",
      "Epoch 39/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6719 - loss: 0.3849 - val_accuracy: 0.6659 - val_loss: 0.3660\n",
      "Epoch 40/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.3557 - val_accuracy: 0.6334 - val_loss: 0.3816\n",
      "Epoch 41/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6631 - loss: 0.3488 - val_accuracy: 0.6654 - val_loss: 0.3596\n",
      "Epoch 42/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6663 - loss: 0.3704 - val_accuracy: 0.6942 - val_loss: 0.3759\n",
      "Epoch 43/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.3535 - val_accuracy: 0.6409 - val_loss: 0.3598\n",
      "Epoch 44/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6631 - loss: 0.3500 - val_accuracy: 0.6649 - val_loss: 0.3461\n",
      "Epoch 45/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6735 - loss: 0.3385 - val_accuracy: 0.6499 - val_loss: 0.3435\n",
      "Epoch 46/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6725 - loss: 0.3392 - val_accuracy: 0.6659 - val_loss: 0.3341\n",
      "Epoch 47/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.3369 - val_accuracy: 0.6645 - val_loss: 0.3174\n",
      "Epoch 48/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6791 - loss: 0.3242 - val_accuracy: 0.6621 - val_loss: 0.3125\n",
      "Epoch 49/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6718 - loss: 0.3222 - val_accuracy: 0.6720 - val_loss: 0.3069\n",
      "Epoch 50/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.3095 - val_accuracy: 0.6711 - val_loss: 0.3011\n",
      "Epoch 51/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6713 - loss: 0.2934 - val_accuracy: 0.6762 - val_loss: 0.3009\n",
      "Epoch 52/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6796 - loss: 0.3088 - val_accuracy: 0.6583 - val_loss: 0.3072\n",
      "Epoch 53/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6768 - loss: 0.3103 - val_accuracy: 0.6725 - val_loss: 0.2844\n",
      "Epoch 54/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6843 - loss: 0.3172 - val_accuracy: 0.6249 - val_loss: 0.3823\n",
      "Epoch 55/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6788 - loss: 0.2792 - val_accuracy: 0.6607 - val_loss: 0.2904\n",
      "Epoch 56/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.2825 - val_accuracy: 0.6706 - val_loss: 0.2752\n",
      "Epoch 57/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.2783 - val_accuracy: 0.6602 - val_loss: 0.2759\n",
      "Epoch 58/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.2949 - val_accuracy: 0.6621 - val_loss: 0.2604\n",
      "Epoch 59/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.2551 - val_accuracy: 0.7012 - val_loss: 0.2730\n",
      "Epoch 60/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6948 - loss: 0.2634 - val_accuracy: 0.6795 - val_loss: 0.2414\n",
      "Epoch 61/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.2394 - val_accuracy: 0.6715 - val_loss: 0.2263\n",
      "Epoch 62/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.2524 - val_accuracy: 0.6678 - val_loss: 0.2240\n",
      "Epoch 63/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.2365 - val_accuracy: 0.6583 - val_loss: 0.2459\n",
      "Epoch 64/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.2078 - val_accuracy: 0.7088 - val_loss: 0.2981\n",
      "Epoch 65/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.2114 - val_accuracy: 0.6946 - val_loss: 0.1901\n",
      "Epoch 66/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.1838 - val_accuracy: 0.6942 - val_loss: 0.1842\n",
      "Epoch 67/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.2080 - val_accuracy: 0.6098 - val_loss: 0.2899\n",
      "Epoch 68/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.1782 - val_accuracy: 0.6970 - val_loss: 0.1606\n",
      "Epoch 69/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.1898 - val_accuracy: 0.6894 - val_loss: 0.1454\n",
      "Epoch 70/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6824 - loss: 0.1771 - val_accuracy: 0.6711 - val_loss: 0.1484\n",
      "Epoch 71/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.1112 - val_accuracy: 0.7083 - val_loss: 0.1254\n",
      "Epoch 72/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.1622 - val_accuracy: 0.6913 - val_loss: 0.1024\n",
      "Epoch 73/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.1505 - val_accuracy: 0.6975 - val_loss: 0.1243\n",
      "Epoch 74/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.0919 - val_accuracy: 0.6984 - val_loss: 0.0863\n",
      "Epoch 75/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.0954 - val_accuracy: 0.6720 - val_loss: 0.0910\n",
      "Epoch 76/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.1328 - val_accuracy: 0.6795 - val_loss: 0.0369\n",
      "Epoch 77/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.0486 - val_accuracy: 0.6777 - val_loss: 0.0310\n",
      "Epoch 78/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.0293 - val_accuracy: 0.4816 - val_loss: 0.8963\n",
      "Epoch 79/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.1205 - val_accuracy: 0.5302 - val_loss: 0.4405\n",
      "Epoch 80/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.0197 - val_accuracy: 0.5273 - val_loss: 0.3750\n",
      "Epoch 81/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.0278 - val_accuracy: 0.6400 - val_loss: 0.0500\n",
      "Epoch 82/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.0292 - val_accuracy: 0.6697 - val_loss: -0.0449\n",
      "Epoch 83/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: -0.1002 - val_accuracy: 0.6244 - val_loss: 0.0213\n",
      "Epoch 84/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: -0.0297 - val_accuracy: 0.6494 - val_loss: 0.1301\n",
      "Epoch 85/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7004 - loss: -0.1656 - val_accuracy: 0.6786 - val_loss: -0.1756\n",
      "Epoch 86/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: -0.1623 - val_accuracy: 0.6880 - val_loss: -0.1895\n",
      "Epoch 87/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7005 - loss: -0.1431 - val_accuracy: 0.7022 - val_loss: -0.2919\n",
      "Epoch 88/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: -0.2258 - val_accuracy: 0.6282 - val_loss: -0.1978\n",
      "Epoch 89/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: -0.2063 - val_accuracy: 0.7163 - val_loss: -0.1786\n",
      "Epoch 90/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: -0.2835 - val_accuracy: 0.4406 - val_loss: 1.9567\n",
      "Epoch 91/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: -0.2866 - val_accuracy: 0.5820 - val_loss: 0.1516\n",
      "Epoch 92/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: -0.3292 - val_accuracy: 0.6192 - val_loss: 1.1162\n",
      "Epoch 93/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: -0.4001 - val_accuracy: 0.6122 - val_loss: 0.6041\n",
      "Epoch 94/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6880 - loss: -0.4252 - val_accuracy: 0.6272 - val_loss: -0.3619\n",
      "Epoch 95/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6716 - loss: -0.4244 - val_accuracy: 0.6503 - val_loss: -0.6421\n",
      "Epoch 96/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: -0.6126 - val_accuracy: 0.6828 - val_loss: -0.8049\n",
      "Epoch 97/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: -0.5627 - val_accuracy: 0.6678 - val_loss: -0.2610\n",
      "Epoch 98/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: -0.7075 - val_accuracy: 0.6089 - val_loss: -0.6894\n",
      "Epoch 99/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: -0.8889 - val_accuracy: 0.5735 - val_loss: -0.4492\n",
      "Epoch 100/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: -1.0521 - val_accuracy: 0.4981 - val_loss: -0.5550\n"
     ]
    }
   ],
   "source": [
    "#? Train the model\n",
    "history_sgd_no_momentum = model_sgd.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: -0.6615\n",
      "MLP (SGD no momentum) Accuracy: 0.6938160061836243\n"
     ]
    }
   ],
   "source": [
    "#? Evaluate accuracy\n",
    "loss_sgd_no_momentum, acc_sgd_no_momentum = model_sgd.evaluate(X_test, y_test)\n",
    "print(\"MLP (SGD no momentum) Accuracy:\", acc_sgd_no_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Momemtum Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4286 - loss: 0.6703 - val_accuracy: 0.5118 - val_loss: 0.6203\n",
      "Epoch 2/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 0.6050 - val_accuracy: 0.6202 - val_loss: 0.5314\n",
      "Epoch 3/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.5245 - val_accuracy: 0.6706 - val_loss: 0.4678\n",
      "Epoch 4/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.4750 - val_accuracy: 0.6607 - val_loss: 0.4239\n",
      "Epoch 5/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6539 - loss: 0.4362 - val_accuracy: 0.6503 - val_loss: 0.3952\n",
      "Epoch 6/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.4144 - val_accuracy: 0.6598 - val_loss: 0.3551\n",
      "Epoch 7/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6655 - loss: 0.3664 - val_accuracy: 0.6692 - val_loss: 0.3002\n",
      "Epoch 8/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.3336 - val_accuracy: 0.6753 - val_loss: 0.2909\n",
      "Epoch 9/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.2890 - val_accuracy: 0.6607 - val_loss: 0.1333\n",
      "Epoch 10/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6771 - loss: 0.2105 - val_accuracy: 0.6616 - val_loss: 0.0610\n",
      "Epoch 11/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.1552 - val_accuracy: 0.6489 - val_loss: 0.3498\n",
      "Epoch 12/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6805 - loss: 0.3211 - val_accuracy: 0.6960 - val_loss: 0.2558\n",
      "Epoch 13/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.3023 - val_accuracy: 0.7003 - val_loss: 0.0238\n",
      "Epoch 14/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6830 - loss: 0.2195 - val_accuracy: 0.6607 - val_loss: 0.2915\n",
      "Epoch 15/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6808 - loss: 0.2430 - val_accuracy: 0.7337 - val_loss: 0.5996\n"
     ]
    }
   ],
   "source": [
    "model_momentum = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer_momentum = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model_momentum.compile(optimizer=optimizer_momentum,\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "history_momentum = model_momentum.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5154 - loss: 0.6238\n",
      "MLP (Momentum) Accuracy: 0.5150829553604126\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Evaluate accuracy\n",
    "loss_momentum, acc_momentum = model_momentum.evaluate(X_test, y_test)\n",
    "print(\"MLP (Momentum) Accuracy:\", acc_momentum)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4059 - loss: 0.6770 - val_accuracy: 0.4453 - val_loss: 0.6161\n",
      "Epoch 2/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.5898 - val_accuracy: 0.5650 - val_loss: 0.5231\n",
      "Epoch 3/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 0.5083 - val_accuracy: 0.6692 - val_loss: 0.4522\n",
      "Epoch 4/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6614 - loss: 0.4494 - val_accuracy: 0.6414 - val_loss: 0.4094\n",
      "Epoch 5/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.4159 - val_accuracy: 0.6758 - val_loss: 0.3842\n",
      "Epoch 6/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6757 - loss: 0.3692 - val_accuracy: 0.6404 - val_loss: 0.3679\n",
      "Epoch 7/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.3352 - val_accuracy: 0.6640 - val_loss: 0.2388\n",
      "Epoch 8/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6741 - loss: 0.2412 - val_accuracy: 0.7234 - val_loss: 0.2507\n",
      "Epoch 9/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 0.1846 - val_accuracy: 0.6334 - val_loss: 0.4529\n",
      "Epoch 10/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: -0.0583 - val_accuracy: 0.7177 - val_loss: -0.4707\n",
      "Epoch 11/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6824 - loss: -0.3209 - val_accuracy: 0.6678 - val_loss: -0.1736\n",
      "Epoch 12/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: -0.1386 - val_accuracy: 0.6494 - val_loss: -0.0288\n",
      "Epoch 13/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: -0.5069 - val_accuracy: 0.5999 - val_loss: 0.5736\n",
      "Epoch 14/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.1015 - val_accuracy: 0.6357 - val_loss: 0.2658\n",
      "Epoch 15/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6712 - loss: -0.2267 - val_accuracy: 0.5245 - val_loss: 0.5894\n"
     ]
    }
   ],
   "source": [
    "model_momentum_nesterov = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer_momentum_nesterov = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model_momentum_nesterov.compile(optimizer=optimizer_momentum_nesterov,\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "history_momentum_nesterov = model_momentum_nesterov.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4398 - loss: 0.6210\n",
      "MLP (Momentum) Accuracy: 0.44532427191734314\n"
     ]
    }
   ],
   "source": [
    "loss_momentum, acc_momentum = model_momentum_nesterov.evaluate(X_test, y_test)\n",
    "print(\"MLP (Momentum) Accuracy:\", acc_momentum)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5544 - loss: 0.6553 - val_accuracy: 0.6494 - val_loss: 0.5083\n",
      "Epoch 2/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6469 - loss: 0.4977 - val_accuracy: 0.6635 - val_loss: 0.4150\n",
      "Epoch 3/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.4163 - val_accuracy: 0.6711 - val_loss: 0.3544\n",
      "Epoch 4/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.3565 - val_accuracy: 0.6871 - val_loss: 0.2943\n",
      "Epoch 5/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6906 - loss: 0.3006 - val_accuracy: 0.7224 - val_loss: 0.2493\n",
      "Epoch 6/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.2404 - val_accuracy: 0.7276 - val_loss: 0.1794\n",
      "Epoch 7/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.1715 - val_accuracy: 0.7262 - val_loss: 0.0982\n",
      "Epoch 8/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.1114 - val_accuracy: 0.7154 - val_loss: 0.0144\n",
      "Epoch 9/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 2.7790e-04 - val_accuracy: 0.7281 - val_loss: -0.1035\n",
      "Epoch 10/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: -0.0852 - val_accuracy: 0.7257 - val_loss: -0.2343\n",
      "Epoch 11/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: -0.2606 - val_accuracy: 0.7370 - val_loss: -0.3950\n",
      "Epoch 12/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: -0.3189 - val_accuracy: 0.7253 - val_loss: -0.5841\n",
      "Epoch 13/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: -0.4703 - val_accuracy: 0.7375 - val_loss: -0.7976\n",
      "Epoch 14/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: -0.8411 - val_accuracy: 0.7295 - val_loss: -1.0749\n",
      "Epoch 15/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: -0.9431 - val_accuracy: 0.7356 - val_loss: -1.3670\n",
      "Epoch 16/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: -1.2488 - val_accuracy: 0.7205 - val_loss: -1.6707\n",
      "Epoch 17/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: -1.5104 - val_accuracy: 0.7328 - val_loss: -2.0580\n",
      "Epoch 18/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: -1.9448 - val_accuracy: 0.7356 - val_loss: -2.4607\n",
      "Epoch 19/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: -2.3410 - val_accuracy: 0.7224 - val_loss: -2.8938\n",
      "Epoch 20/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: -2.6203 - val_accuracy: 0.7290 - val_loss: -3.3853\n",
      "Epoch 21/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: -2.9145 - val_accuracy: 0.7352 - val_loss: -3.8996\n",
      "Epoch 22/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: -3.6919 - val_accuracy: 0.7210 - val_loss: -4.4941\n",
      "Epoch 23/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: -4.0539 - val_accuracy: 0.7243 - val_loss: -5.0994\n",
      "Epoch 24/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: -4.6205 - val_accuracy: 0.7262 - val_loss: -5.7998\n",
      "Epoch 25/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: -4.9961 - val_accuracy: 0.7158 - val_loss: -6.5481\n",
      "Epoch 26/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: -6.5289 - val_accuracy: 0.7347 - val_loss: -7.3067\n",
      "Epoch 27/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: -6.6774 - val_accuracy: 0.7337 - val_loss: -8.1890\n",
      "Epoch 28/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: -7.3120 - val_accuracy: 0.7267 - val_loss: -9.0882\n",
      "Epoch 29/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: -7.7244 - val_accuracy: 0.7281 - val_loss: -10.0314\n",
      "Epoch 30/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: -9.8166 - val_accuracy: 0.7121 - val_loss: -10.9543\n",
      "Epoch 31/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: -10.7096 - val_accuracy: 0.7361 - val_loss: -12.0166\n",
      "Epoch 32/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: -10.6001 - val_accuracy: 0.7201 - val_loss: -13.1038\n",
      "Epoch 33/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: -12.1220 - val_accuracy: 0.7234 - val_loss: -14.2895\n",
      "Epoch 34/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: -13.5552 - val_accuracy: 0.7290 - val_loss: -15.5488\n",
      "Epoch 35/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: -14.8667 - val_accuracy: 0.7125 - val_loss: -16.7479\n",
      "Epoch 36/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: -14.1868 - val_accuracy: 0.7333 - val_loss: -18.1478\n",
      "Epoch 37/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: -16.1572 - val_accuracy: 0.7201 - val_loss: -19.5527\n",
      "Epoch 38/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: -15.7635 - val_accuracy: 0.7257 - val_loss: -21.0092\n",
      "Epoch 39/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: -19.2333 - val_accuracy: 0.7262 - val_loss: -22.5386\n",
      "Epoch 40/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: -19.8144 - val_accuracy: 0.7102 - val_loss: -24.0541\n",
      "Epoch 41/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: -21.3382 - val_accuracy: 0.7248 - val_loss: -25.8040\n",
      "Epoch 42/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: -26.0714 - val_accuracy: 0.7215 - val_loss: -27.4789\n",
      "Epoch 43/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: -25.9884 - val_accuracy: 0.7333 - val_loss: -29.2537\n",
      "Epoch 44/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: -29.3165 - val_accuracy: 0.7116 - val_loss: -31.0955\n",
      "Epoch 45/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7131 - loss: -31.9696 - val_accuracy: 0.7262 - val_loss: -33.0695\n",
      "Epoch 46/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: -30.2756 - val_accuracy: 0.7008 - val_loss: -34.9201\n",
      "Epoch 47/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: -34.5873 - val_accuracy: 0.7281 - val_loss: -37.1276\n",
      "Epoch 48/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: -33.0345 - val_accuracy: 0.7286 - val_loss: -39.3136\n",
      "Epoch 49/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7202 - loss: -35.6533 - val_accuracy: 0.7229 - val_loss: -41.5226\n",
      "Epoch 50/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: -37.8725 - val_accuracy: 0.7083 - val_loss: -43.7875\n",
      "Epoch 51/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: -39.3945 - val_accuracy: 0.7154 - val_loss: -46.0673\n",
      "Epoch 52/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: -41.5955 - val_accuracy: 0.7224 - val_loss: -48.4903\n",
      "Epoch 53/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: -45.2472 - val_accuracy: 0.7300 - val_loss: -51.0116\n",
      "Epoch 54/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: -54.1981 - val_accuracy: 0.7149 - val_loss: -53.4565\n",
      "Epoch 55/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: -52.3374 - val_accuracy: 0.7172 - val_loss: -56.1702\n",
      "Epoch 56/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: -50.1341 - val_accuracy: 0.7191 - val_loss: -58.8197\n",
      "Epoch 57/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: -54.7317 - val_accuracy: 0.7309 - val_loss: -61.7446\n",
      "Epoch 58/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: -62.8208 - val_accuracy: 0.7253 - val_loss: -64.4313\n",
      "Epoch 59/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: -61.4956 - val_accuracy: 0.7182 - val_loss: -67.5390\n",
      "Epoch 60/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: -64.8595 - val_accuracy: 0.7121 - val_loss: -70.7291\n",
      "Epoch 61/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: -64.3182 - val_accuracy: 0.7286 - val_loss: -74.0067\n",
      "Epoch 62/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: -71.6085 - val_accuracy: 0.7172 - val_loss: -77.2074\n",
      "Epoch 63/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: -75.0991 - val_accuracy: 0.7286 - val_loss: -80.6468\n",
      "Epoch 64/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: -72.3711 - val_accuracy: 0.7253 - val_loss: -83.9743\n",
      "Epoch 65/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: -76.7663 - val_accuracy: 0.7295 - val_loss: -87.6123\n",
      "Epoch 66/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: -75.5532 - val_accuracy: 0.7286 - val_loss: -91.2448\n",
      "Epoch 67/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: -89.7470 - val_accuracy: 0.7220 - val_loss: -94.7945\n",
      "Epoch 68/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: -90.5792 - val_accuracy: 0.7248 - val_loss: -98.7252\n",
      "Epoch 69/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: -93.1728 - val_accuracy: 0.7149 - val_loss: -102.5980\n",
      "Epoch 70/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: -94.3633 - val_accuracy: 0.7304 - val_loss: -106.7785\n",
      "Epoch 71/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: -90.5325 - val_accuracy: 0.6810 - val_loss: -110.4630\n",
      "Epoch 72/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: -86.7522 - val_accuracy: 0.7224 - val_loss: -115.2029\n",
      "Epoch 73/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: -104.7612 - val_accuracy: 0.7045 - val_loss: -119.4085\n",
      "Epoch 74/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: -102.9559 - val_accuracy: 0.7243 - val_loss: -124.0220\n",
      "Epoch 75/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: -106.6495 - val_accuracy: 0.7196 - val_loss: -128.5568\n",
      "Epoch 76/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: -115.2217 - val_accuracy: 0.7286 - val_loss: -133.3413\n",
      "Epoch 77/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: -114.0176 - val_accuracy: 0.7262 - val_loss: -138.1378\n",
      "Epoch 78/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: -133.7431 - val_accuracy: 0.7257 - val_loss: -142.8895\n",
      "Epoch 79/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: -136.3763 - val_accuracy: 0.7248 - val_loss: -147.8460\n",
      "Epoch 80/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: -136.6422 - val_accuracy: 0.7224 - val_loss: -152.9384\n",
      "Epoch 81/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: -143.5357 - val_accuracy: 0.7022 - val_loss: -157.9640\n",
      "Epoch 82/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7202 - loss: -153.2289 - val_accuracy: 0.7111 - val_loss: -163.6721\n",
      "Epoch 83/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: -150.9725 - val_accuracy: 0.7220 - val_loss: -169.2249\n",
      "Epoch 84/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: -175.6697 - val_accuracy: 0.6923 - val_loss: -174.3922\n",
      "Epoch 85/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: -184.3757 - val_accuracy: 0.7205 - val_loss: -180.6161\n",
      "Epoch 86/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: -165.9975 - val_accuracy: 0.7125 - val_loss: -186.3132\n",
      "Epoch 87/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: -184.7283 - val_accuracy: 0.7201 - val_loss: -192.3085\n",
      "Epoch 88/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: -172.0321 - val_accuracy: 0.7172 - val_loss: -198.3154\n",
      "Epoch 89/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: -215.0553 - val_accuracy: 0.7177 - val_loss: -204.5622\n",
      "Epoch 90/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: -203.6927 - val_accuracy: 0.7187 - val_loss: -210.9286\n",
      "Epoch 91/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: -182.7626 - val_accuracy: 0.7059 - val_loss: -217.1585\n",
      "Epoch 92/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7078 - loss: -209.6853 - val_accuracy: 0.6970 - val_loss: -223.7366\n",
      "Epoch 93/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: -221.7569 - val_accuracy: 0.6866 - val_loss: -229.6301\n",
      "Epoch 94/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7139 - loss: -213.9358 - val_accuracy: 0.6748 - val_loss: -236.1412\n",
      "Epoch 95/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: -213.5313 - val_accuracy: 0.7102 - val_loss: -243.8380\n",
      "Epoch 96/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: -214.5190 - val_accuracy: 0.7022 - val_loss: -250.6019\n",
      "Epoch 97/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: -219.1587 - val_accuracy: 0.7116 - val_loss: -257.6898\n",
      "Epoch 98/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: -255.4637 - val_accuracy: 0.6993 - val_loss: -264.6424\n",
      "Epoch 99/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: -233.8132 - val_accuracy: 0.7088 - val_loss: -272.3810\n",
      "Epoch 100/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: -225.6763 - val_accuracy: 0.6989 - val_loss: -279.7980\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_momentum_adam = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer_momentum_adam = Adam(learning_rate=0.0001)\n",
    "model_momentum_adam.compile(optimizer=optimizer_momentum_adam,\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "history_momentum_adam = model_momentum_adam.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,  # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6922 - loss: -251.9148\n",
      "MLP (Momentum) Accuracy: 0.6904222965240479\n"
     ]
    }
   ],
   "source": [
    "loss_momentum, acc_momentum = model_momentum_adam.evaluate(X_test, y_test)\n",
    "print(\"MLP (Momentum) Accuracy:\", acc_momentum)# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load data with `fashion_mnist.load_data()`.\n",
    "2) Normalize the pixel values to [0,1].\n",
    "3) Flatten each 28×28 image into a single 784-dimensional vector.\n",
    "4) Convert labels (0–9) to one-hot encoding.\n",
    "5) Build a simple MLP \n",
    "6) Train with different optimizers (SGD vs. SGD+momentum vs. Adam).\n",
    "7) Compare test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\IDE\\Anaconda\\envs\\vision\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 1.3383 - val_accuracy: 0.7828 - val_loss: 0.6366\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.6026 - val_accuracy: 0.8188 - val_loss: 0.5330\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.5204 - val_accuracy: 0.8247 - val_loss: 0.4953\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.4788 - val_accuracy: 0.8318 - val_loss: 0.4728\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.4623 - val_accuracy: 0.8419 - val_loss: 0.4521\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4435 - val_accuracy: 0.8434 - val_loss: 0.4445\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.4299 - val_accuracy: 0.8490 - val_loss: 0.4350\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8553 - loss: 0.4178 - val_accuracy: 0.8454 - val_loss: 0.4362\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.4120 - val_accuracy: 0.8533 - val_loss: 0.4163\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3995 - val_accuracy: 0.8553 - val_loss: 0.4114\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.3918 - val_accuracy: 0.8540 - val_loss: 0.4168\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.3854 - val_accuracy: 0.8584 - val_loss: 0.4025\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3799 - val_accuracy: 0.8617 - val_loss: 0.3927\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3768 - val_accuracy: 0.8631 - val_loss: 0.3909\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3668 - val_accuracy: 0.8583 - val_loss: 0.3982\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.3617 - val_accuracy: 0.8543 - val_loss: 0.4111\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3623 - val_accuracy: 0.8668 - val_loss: 0.3802\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.3450 - val_accuracy: 0.8667 - val_loss: 0.3792\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.3413 - val_accuracy: 0.8672 - val_loss: 0.3786\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.3424 - val_accuracy: 0.8695 - val_loss: 0.3730\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3387 - val_accuracy: 0.8708 - val_loss: 0.3669\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.3330 - val_accuracy: 0.8710 - val_loss: 0.3668\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.3339 - val_accuracy: 0.8707 - val_loss: 0.3655\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3254 - val_accuracy: 0.8721 - val_loss: 0.3704\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3262 - val_accuracy: 0.8730 - val_loss: 0.3595\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.3197 - val_accuracy: 0.8735 - val_loss: 0.3594\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.3157 - val_accuracy: 0.8685 - val_loss: 0.3700\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.3110 - val_accuracy: 0.8757 - val_loss: 0.3548\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3035 - val_accuracy: 0.8717 - val_loss: 0.3634\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.3021 - val_accuracy: 0.8752 - val_loss: 0.3525\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.3019 - val_accuracy: 0.8767 - val_loss: 0.3474\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2997 - val_accuracy: 0.8751 - val_loss: 0.3533\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3002 - val_accuracy: 0.8770 - val_loss: 0.3522\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2939 - val_accuracy: 0.8798 - val_loss: 0.3429\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2944 - val_accuracy: 0.8764 - val_loss: 0.3476\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2930 - val_accuracy: 0.8798 - val_loss: 0.3385\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.2878 - val_accuracy: 0.8730 - val_loss: 0.3548\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2803 - val_accuracy: 0.8802 - val_loss: 0.3393\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.2813 - val_accuracy: 0.8797 - val_loss: 0.3415\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2782 - val_accuracy: 0.8792 - val_loss: 0.3461\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2768 - val_accuracy: 0.8751 - val_loss: 0.3538\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2724 - val_accuracy: 0.8813 - val_loss: 0.3395\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2750 - val_accuracy: 0.8796 - val_loss: 0.3392\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.2667 - val_accuracy: 0.8785 - val_loss: 0.3426\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2693 - val_accuracy: 0.8850 - val_loss: 0.3335\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2649 - val_accuracy: 0.8827 - val_loss: 0.3371\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2606 - val_accuracy: 0.8756 - val_loss: 0.3517\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2648 - val_accuracy: 0.8842 - val_loss: 0.3352\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2634 - val_accuracy: 0.8827 - val_loss: 0.3311\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2643 - val_accuracy: 0.8726 - val_loss: 0.3618\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8755 - loss: 0.3514\n",
      "Fashion MNIST - MLP with plain SGD: 0.8765000104904175\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 8.1 Load the Fashion MNIST dataset\n",
    "(X_train_fmnist, y_train_fmnist), (X_test_fmnist, y_test_fmnist) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "X_train_fmnist = X_train_fmnist / 255.0\n",
    "X_test_fmnist = X_test_fmnist / 255.0\n",
    "\n",
    "# Flatten images (28x28) to 784-dim vectors\n",
    "X_train_fmnist = X_train_fmnist.reshape(-1, 784)\n",
    "X_test_fmnist = X_test_fmnist.reshape(-1, 784)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "y_train_fmnist = to_categorical(y_train_fmnist, 10)\n",
    "y_test_fmnist = to_categorical(y_test_fmnist, 10)\n",
    "\n",
    "# 8.2 Build a simple model function to reuse\n",
    "def build_fmnist_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))  # 10 classes\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "global_epoch = 50\n",
    "\n",
    "#? 1) Train with plain SGD\n",
    "model_fmnist_sgd = build_fmnist_model(SGD(learning_rate=0.01))\n",
    "history_fmnist_sgd = model_fmnist_sgd.fit(\n",
    "    X_train_fmnist, y_train_fmnist,\n",
    "    validation_split=0.2,\n",
    "    epochs=global_epoch,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "loss_sgd, acc_sgd = model_fmnist_sgd.evaluate(X_test_fmnist, y_test_fmnist)\n",
    "\n",
    "# 8.2 Compare the test accuracies among these three runs\n",
    "print(\"Fashion MNIST - MLP with plain SGD:\", acc_sgd)\n",
    "# print for momentum, Adam after you train them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.8344 - val_accuracy: 0.8332 - val_loss: 0.4590\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4336 - val_accuracy: 0.8506 - val_loss: 0.4086\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3886 - val_accuracy: 0.8617 - val_loss: 0.3831\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3499 - val_accuracy: 0.8698 - val_loss: 0.3631\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3300 - val_accuracy: 0.8675 - val_loss: 0.3584\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3188 - val_accuracy: 0.8771 - val_loss: 0.3356\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.3067 - val_accuracy: 0.8767 - val_loss: 0.3453\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2896 - val_accuracy: 0.8800 - val_loss: 0.3308\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2778 - val_accuracy: 0.8829 - val_loss: 0.3282\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2847 - val_accuracy: 0.8871 - val_loss: 0.3180\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2657 - val_accuracy: 0.8813 - val_loss: 0.3278\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2550 - val_accuracy: 0.8823 - val_loss: 0.3281\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2495 - val_accuracy: 0.8808 - val_loss: 0.3345\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2350 - val_accuracy: 0.8880 - val_loss: 0.3126\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2292 - val_accuracy: 0.8907 - val_loss: 0.3078\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2295 - val_accuracy: 0.8854 - val_loss: 0.3298\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2184 - val_accuracy: 0.8877 - val_loss: 0.3178\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2158 - val_accuracy: 0.8907 - val_loss: 0.3117\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2088 - val_accuracy: 0.8857 - val_loss: 0.3188\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2027 - val_accuracy: 0.8879 - val_loss: 0.3299\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2040 - val_accuracy: 0.8899 - val_loss: 0.3078\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1930 - val_accuracy: 0.8852 - val_loss: 0.3342\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1986 - val_accuracy: 0.8908 - val_loss: 0.3198\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1887 - val_accuracy: 0.8881 - val_loss: 0.3243\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.1808 - val_accuracy: 0.8815 - val_loss: 0.3444\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.3317\n",
      "Fashion MNIST - MLP with plain SGD: 0.886900007724762\n"
     ]
    }
   ],
   "source": [
    "#? 2) Use nesterov optimizer\n",
    "optimizer_momentum = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model_fmnist_sgd = build_fmnist_model(optimizer_momentum)\n",
    "history_fmnist_sgd = model_fmnist_sgd.fit(\n",
    "    X_train_fmnist, y_train_fmnist,\n",
    "    validation_split=0.2,\n",
    "    epochs=global_epoch,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss_sgd, acc_sgd = model_fmnist_sgd.evaluate(X_test_fmnist, y_test_fmnist)\n",
    "\n",
    "# 8.2 Compare the test accuracies among these three runs\n",
    "print(\"Fashion MNIST - MLP with plain SGD:\", acc_sgd)\n",
    "# print for momentum, Adam after you train them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.8534 - val_accuracy: 0.8376 - val_loss: 0.4665\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.4314 - val_accuracy: 0.8485 - val_loss: 0.4263\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3796 - val_accuracy: 0.8590 - val_loss: 0.3914\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3516 - val_accuracy: 0.8647 - val_loss: 0.3898\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.3363 - val_accuracy: 0.8642 - val_loss: 0.3722\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3130 - val_accuracy: 0.8667 - val_loss: 0.3714\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2972 - val_accuracy: 0.8761 - val_loss: 0.3450\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2838 - val_accuracy: 0.8831 - val_loss: 0.3280\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2704 - val_accuracy: 0.8816 - val_loss: 0.3323\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2676 - val_accuracy: 0.8822 - val_loss: 0.3336\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4793\n",
      "Fashion MNIST - MLP with plain SGD: 0.829200029373169\n"
     ]
    }
   ],
   "source": [
    "#? 2) Use nesterov optimizer\n",
    "optimizer_momentum_nesterov = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model_fmnist_sgd = build_fmnist_model(optimizer_momentum_nesterov)\n",
    "history_fmnist_sgd = model_fmnist_sgd.fit(\n",
    "    X_train_fmnist, y_train_fmnist,\n",
    "    validation_split=0.2,\n",
    "    epochs=global_epoch,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss_sgd, acc_sgd = model_fmnist_sgd.evaluate(X_test_fmnist, y_test_fmnist)\n",
    "\n",
    "# 8.2 Compare the test accuracies among these three runs\n",
    "print(\"Fashion MNIST - MLP with plain SGD:\", acc_sgd)\n",
    "# print for momentum, Adam after you train them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.7177 - val_accuracy: 0.8480 - val_loss: 0.4246\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3877 - val_accuracy: 0.8562 - val_loss: 0.4075\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.3441 - val_accuracy: 0.8718 - val_loss: 0.3520\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3099 - val_accuracy: 0.8767 - val_loss: 0.3359\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2984 - val_accuracy: 0.8846 - val_loss: 0.3293\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2833 - val_accuracy: 0.8828 - val_loss: 0.3309\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2736 - val_accuracy: 0.8836 - val_loss: 0.3298\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2556 - val_accuracy: 0.8787 - val_loss: 0.3324\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2551 - val_accuracy: 0.8861 - val_loss: 0.3213\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2359 - val_accuracy: 0.8801 - val_loss: 0.3366\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.4405\n",
      "Fashion MNIST - MLP with plain SGD: 0.8418999910354614\n"
     ]
    }
   ],
   "source": [
    "#? 3) Adam\n",
    "optimizer_momentum_adam = Adam(learning_rate=0.001)\n",
    "model_fmnist_sgd = build_fmnist_model(optimizer_momentum_adam)\n",
    "history_fmnist_sgd = model_fmnist_sgd.fit(\n",
    "    X_train_fmnist, y_train_fmnist,\n",
    "    validation_split=0.2,\n",
    "    epochs=global_epoch,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss_sgd, acc_sgd = model_fmnist_sgd.evaluate(X_test_fmnist, y_test_fmnist)\n",
    "\n",
    "# 8.2 Compare the test accuracies among these three runs\n",
    "print(\"Fashion MNIST - MLP with plain SGD:\", acc_sgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

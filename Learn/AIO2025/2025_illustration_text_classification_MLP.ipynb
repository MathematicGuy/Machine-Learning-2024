{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_DSNYXLGn3C"
   },
   "source": [
    "## Text Classification - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219310,
     "status": "ok",
     "timestamp": 1738637694185,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "ZEPrpzVVH4rQ",
    "outputId": "5939cf79-583d-4ca3-ba61-f2c6a4dc9b2a"
   },
   "outputs": [],
   "source": [
    "# !pip install -U torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSTqG7X8O82N"
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3976,
     "status": "ok",
     "timestamp": 1738637698160,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "HjFoMLulF4jS"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "corpus = [\n",
    "    \"Deepseek sell off stock market\",\n",
    "    \"Deepseek release all their technical documents\"\n",
    "]\n",
    "data_size = len(corpus)\n",
    "\n",
    "# 0: negative - 1: positive\n",
    "labels = [0, 1]\n",
    "\n",
    "# Define the max vocabulary size and sequence length\n",
    "vocab_size = 8\n",
    "sequence_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1738637698160,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "bvYUgYBZoymB",
    "outputId": "e320af8d-3e96-413f-b1a9-f99d64e2a0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepseek', 'sell', 'off', 'stock', 'market']\n",
      "['deepseek', 'release', 'all', 'their', 'technical', 'documents']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "# version 0.17.0\n",
    "\n",
    "sample1 = corpus[0]\n",
    "sample2 = corpus[1]\n",
    "\n",
    "#Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "sample1_tokens = tokenizer(sample1)\n",
    "sample2_tokens = tokenizer(sample2)\n",
    "\n",
    "print(sample1_tokens)\n",
    "print(sample2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "G6gmk_rDM11u",
    "outputId": "93dbc9c2-1047-41d4-f7d4-9c9941ca13a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 6, 0, 5]\n",
      "[2, 7, 3, 0, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "sample1_ids = [vocab[token] for token in sample1_tokens]\n",
    "sample2_ids = [vocab[token] for token in sample2_tokens]\n",
    "\n",
    "print(sample1_ids)\n",
    "print(sample2_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "wPEte3mnF4c0",
    "outputId": "718a35e7-692d-41c7-f433-7a12fd8bbe62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'release': 7,\n",
       " 'off': 6,\n",
       " 'market': 5,\n",
       " 'documents': 4,\n",
       " 'deepseek': 2,\n",
       " '<pad>': 1,\n",
       " 'all': 3,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(corpus),\n",
    "                                  max_tokens=vocab_size,\n",
    "                                  specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "6Qcwb_J9F4aR"
   },
   "outputs": [],
   "source": [
    "# Tokenize and numericalize your samples\n",
    "def vectorize(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab[token] for token in tokens][:sequence_length]\n",
    "    \n",
    "    #? add padding for blank space left in sequence_length\n",
    "    #? multiply list example: [0] * 2 = [0, 0] \n",
    "    #? list addition: [1, 2] + [0]*2 = [1, 2, 0, 0]\n",
    "    #? (sequence_length - len(tokens) mean adding the special token vocab[\"<pad>\"] \n",
    "    #? to token_ids list by (sequence_length - current_sequence_length). \n",
    "    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    \n",
    "    return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Vectorize the samples\n",
    "corpus_ids = []\n",
    "for sentence in corpus:\n",
    "    corpus_ids.append(vectorize(sentence, vocab, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "KfoTpnTxML6i",
    "outputId": "5bd0e16e-28f5-47b5-ff64-2388d12ab3de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2, 0, 6, 0, 5]), tensor([2, 7, 3, 0, 0])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "sYTUNNQfF4Xh",
    "outputId": "180a2054-b3fe-48b5-b255-a13b0b03d010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 6, 0, 5])\n",
      "tensor([2, 7, 3, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for v in corpus_ids:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738637698161,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "ZwudWVGDTDd-",
    "outputId": "432b9951-df2f-4949-d3ab-9c4346801593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1882,  0.5530],\n",
      "        [ 1.7840, -0.8278],\n",
      "        [ 1.0281, -1.9094],\n",
      "        [-1.3083, -0.0987],\n",
      "        [ 0.2293,  1.3255],\n",
      "        [ 0.4058, -0.6624],\n",
      "        [ 0.5582,  0.0786],\n",
      "        [ 0.4309, -1.3067]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8\n",
    "embedding_dim = 2\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "custom_weights = torch.tensor( [[-0.1882,  0.5530],\n",
    "                                [ 1.7840, -0.8278],\n",
    "                                [ 1.0281, -1.9094],\n",
    "                                [-1.3083, -0.0987],\n",
    "                                [ 0.2293,  1.3255],\n",
    "                                [ 0.4058, -0.6624],\n",
    "                                [ 0.5582,  0.0786],\n",
    "                                [ 0.4309, -1.3067]]).float()\n",
    "embedding.weight = nn.Parameter(custom_weights)\n",
    "\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738637698162,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "zk11cVlLF4Uw"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, 2)\n",
    "custom_weights = torch.tensor( [[-0.1882,  0.5530],\n",
    "                                [ 1.7840, -0.8278],\n",
    "                                [ 1.0281, -1.9094],\n",
    "                                [-1.3083, -0.0987],\n",
    "                                [ 0.2293,  1.3255],\n",
    "                                [ 0.4058, -0.6624],\n",
    "                                [ 0.5582,  0.0786],\n",
    "                                [ 0.4309, -1.3067]]).float()\n",
    "embedding.weight = nn.Parameter(custom_weights)\n",
    "\n",
    "\n",
    "fc = nn.Linear(10, 2)\n",
    "fc_weights = torch.tensor( [[0.2108, -0.0074,  0.2760,  0.2325, -0.0518, -0.1876,  0.0194, 0.0378, 0.0210, 0.2982],\n",
    "                            [0.0284,  0.2968, -0.0260,  0.1251, -0.0282,  0.0175, -0.1817, 0.2483, 0.2338, 0.2985]]).float()\n",
    "fc.weight = nn.Parameter(fc_weights)\n",
    "\n",
    "fc_bias = torch.tensor([-0.3049,  0.1028]).float()\n",
    "fc.bias = nn.Parameter(fc_bias)\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "model = nn.Sequential(embedding, flatten, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738637698162,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "bqJS2A5TZOmk",
    "outputId": "c148e465-af2d-439f-ef5b-220e07a4049e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Embedding(8, 2)\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5113,
     "status": "ok",
     "timestamp": 1738637703271,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "TfAf-_07JKLP"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                             lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD0znSHQbRgc"
   },
   "source": [
    "# Hand on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "vvIwyszTa0A0"
   },
   "outputs": [],
   "source": [
    "input_1 = torch.tensor([[2, 0, 6, 0, 5]], dtype=torch.long)\n",
    "label_1 = torch.tensor([0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "e7xYmI0xa0D8",
    "outputId": "61ededdf-273b-4184-ace1-905dfe61e801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Output:\n",
      " tensor([[[ 1.0281, -1.9094],\n",
      "         [-0.1882,  0.5530],\n",
      "         [ 0.5582,  0.0786],\n",
      "         [-0.1882,  0.5530],\n",
      "         [ 0.4058, -0.6624]]], grad_fn=<EmbeddingBackward0>) torch.Size([1, 5, 2])\n",
      "Flattened Output:\n",
      " torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "embedded_output = embedding(input_1)\n",
    "print(\"Embedded Output:\\n\", embedded_output, embedded_output.shape)\n",
    "flattened_output = flatten(embedded_output)\n",
    "print(\"Flattened Output:\\n\", flattened_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "a_GYyox_d4eR",
    "outputId": "63e9ddd8-332c-4337-e538-6c1798fa1911"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0284,  0.2968, -0.0260,  0.1251, -0.0282,  0.0175, -0.1817,  0.2483,\n",
       "         0.2338,  0.2985])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = fc_weights[0]\n",
    "w2 = fc_weights[1]\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "16y82dEFdfDn",
    "outputId": "efa4cda4-fb58-4db2-9391-612acc8f482b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.2167, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0141, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.0519, grad_fn=<MulBackward0>),\n",
       "  tensor(0.1286, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.0289, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.0147, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.0037, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0209, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0085, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.1975, grad_fn=<MulBackward0>)],\n",
       " tensor(0.0921, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i, x in enumerate(flattened_output[0]):\n",
    "    result.append(x * w1[i])\n",
    "\n",
    "result, sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "2WHPgC8kdfGu",
    "outputId": "7f97d42b-b14e-4a81-85a5-85c955a1b8c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.0292, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.5667, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0049, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0692, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.0157, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0014, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0342, grad_fn=<MulBackward0>),\n",
       "  tensor(0.1373, grad_fn=<MulBackward0>),\n",
       "  tensor(0.0949, grad_fn=<MulBackward0>),\n",
       "  tensor(-0.1977, grad_fn=<MulBackward0>)],\n",
       " tensor(-0.4091, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i, x in enumerate(flattened_output[0]):\n",
    "    result.append(x * w2[i])\n",
    "\n",
    "result, sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "3Xueofw8beOk",
    "outputId": "75420b9f-428b-4c3c-8236-e384e0517f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Output:\n",
      " tensor([[-0.2128, -0.3063]], grad_fn=<AddmmBackward0>) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "fc_output = fc(flattened_output)\n",
    "print(\"FC Output:\\n\", fc_output, fc_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "JNgXEqTKwFAl",
    "outputId": "d72710de-906c-4b8b-dcd6-0afe06de9c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083177846081321"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.e**(-0.2128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "sJQ1BpB3wK5E",
    "outputId": "09adb4bc-c72e-48cb-8eba-f8d01f919905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7361657366043477"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e**(-0.3063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "KhLnNv3txJ51",
    "outputId": "c4d40e48-2e20-477d-c9ff-3e9a4ad60dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4765943671090968"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7361/1.5445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZU6ltI4O_2u"
   },
   "source": [
    "## Train sample-1 once, and check gradient and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "D_wTfOnzJOQ_",
    "outputId": "e2b51579-1f7e-418d-fcc8-7821814f2f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2128, -0.3063]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.5234, 0.4766]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.6475, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# first sample\n",
    "\n",
    "input_1 = torch.tensor([[2, 0, 6, 0, 5]], dtype=torch.long)\n",
    "label_1 = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(input_1)\n",
    "print(outputs)\n",
    "print(torch.softmax(outputs, axis=-1))\n",
    "\n",
    "loss = criterion(outputs, label_1)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738637703272,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "IZ1taeNKJP_D",
    "outputId": "4a21e15b-fc63-46f0-827a-af57e110695f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " embedding.weight \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.1642,  0.5481],\n",
      "        [ 1.7840, -0.8278],\n",
      "        [ 1.0368, -1.9239],\n",
      "        [-1.3083, -0.0987],\n",
      "        [ 0.2293,  1.3255],\n",
      "        [ 0.3957, -0.6624],\n",
      "        [ 0.5571,  0.0688],\n",
      "        [ 0.4309, -1.3067]], requires_grad=True)\n",
      "\n",
      " embedding.weight.grad \n",
      "\n",
      "tensor([[-2.3980e-01,  4.9141e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [-8.6939e-02,  1.4499e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0143e-01,  1.4298e-04],\n",
      "        [ 1.1249e-02,  9.7758e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "\n",
      " fc.weight \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 0.2598, -0.0984,  0.2670,  0.2589, -0.0252, -0.1839,  0.0104,  0.0642,\n",
      "          0.0403,  0.2666],\n",
      "        [-0.0206,  0.3878, -0.0170,  0.0987, -0.0548,  0.0138, -0.1727,  0.2219,\n",
      "          0.2145,  0.3301]], requires_grad=True)\n",
      "\n",
      " fc.bias \n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.2572,  0.0551], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n embedding.weight \\n\")\n",
    "print(embedding.weight)\n",
    "\n",
    "print(\"\\n embedding.weight.grad \\n\")\n",
    "print(embedding.weight.grad)\n",
    "\n",
    "print(\"\\n fc.weight \\n\")\n",
    "print(fc.weight)\n",
    "\n",
    "print(\"\\n fc.bias \\n\")\n",
    "print(fc.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp-XS4GPPJ1W"
   },
   "source": [
    "## check if the loss reduces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738637703273,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "3g1p9TCwJSo2",
    "outputId": "f2a91adb-ff26-46a6-a905-dd5d617dcdf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1456, -0.6688]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6930, 0.3070]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.3667, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "outputs = model(input_1)\n",
    "print(outputs)\n",
    "print(torch.softmax(outputs, axis=-1))\n",
    "\n",
    "loss = criterion(outputs, label_1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1738637703273,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "4wYNc6ZxPecv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWqBVTHMPP7t"
   },
   "source": [
    "## Train several epochs (ignore this part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1738637703273,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "ftjA9ZnzJZFR",
    "outputId": "3cf3c854-fa0e-49f9-8d62-2fa9e6214c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2824, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[4, 3, 0, 6, 3],\n",
    "                       [2, 5, 7, 2, 0]], dtype=torch.long)\n",
    "labels = torch.tensor([0, 1], dtype=torch.long)\n",
    "\n",
    "for _ in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmwD9JyVQK-2"
   },
   "source": [
    "## Check if the model has adready learned sucessfuly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738637703273,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "jRkcGw8OQFwX",
    "outputId": "5869d3b7-b105-44d0-a302-f8ab29153ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2058, -0.8800],\n",
      "        [-1.3359,  0.4520]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7476, 0.2524],\n",
      "        [0.1433, 0.8567]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "print(outputs)\n",
    "print(torch.softmax(outputs, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738637703273,
     "user": {
      "displayName": "GCVAI",
      "userId": "03225888007990411748"
     },
     "user_tz": -420
    },
    "id": "npVHuf9gQYKc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
